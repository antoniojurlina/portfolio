{
  
    
        "post0": {
            "title": "Title",
            "content": "Agora - A Dark Web Marketplace . Data analysis and visualization . Antonio Jurlina . import pandas as pd import numpy as np import matplotlib.pyplot as plt import os import warnings warnings.filterwarnings(&quot;ignore&quot;) os.chdir(&#39;/Users/antoniojurlina/Projects/learning_python/data/&#39;) . A few years ago, a reddit user called usheep scraped a DarkWeb marketplace called the Agora for a list of vendors, their identities and products, while threatening to expose them all as blackmail. Eventually, this data set made it to the general public, and while usheep disappeared, we have thousands of rows of vendors, items, categories, descriptions and prices in an organized data set that contains drugs, weapons, books, services, and more. There are over 100,000 unique observations spanning year 2014. My goal is to analyze this data set and explore some common items being sold, as well as the usual prices across categories. . Although there is over 1.6TB of uncompressed, scraped data of dark web sales available out there, the goal of this project will be to look at the Kaggle published subset which is around 30MB and contains ~100,000 observations. The data set is available as a direct .csv download with a Kaggle account. Additonally, since all the prices listed in this data set are in Bitcoin, I went to Coindesk and downloaded the daily closing price of Bitcoin in US Dollar amounts, for that whole period. This data set will be used to make the costs more comprehensible by converting them to current USD prices. . dw_data = pd.read_csv(&quot;Agora.csv&quot;, usecols=[&#39;Vendor&#39;, &#39; Category&#39;, &#39; Item&#39;, &#39; Item Description&#39;, &#39; Price&#39;, &#39; Rating&#39;]) .rename(columns={&#39;Vendor&#39;:&#39;vendor&#39;, &#39; Category&#39;:&#39;category&#39;, &#39; Item&#39;:&#39;item&#39;, &#39; Item Description&#39;:&#39;description&#39;, &#39; Price&#39;:&#39;price&#39;, &#39; Rating&#39;:&#39;rating&#39;}) # Importing Bitcoin data and selecting out the relevant column bitcoin = pd.read_csv(&quot;BTC_USD_2014-01-02_2015-01-01-CoinDesk.csv&quot;) inflation = 0.1186 # the inflation rate between 2014 and 2021 bitcoin = bitcoin.iloc[:,2]*(1+inflation) . The Agora data set sample, as it is currently in the memory, is shown below. The variables that need to be cleaned up further are category, price, and rating. . Category: There are categories and subcategories within this column that need to be split into separate columns. | Price: This a string because the word BTC is present in each and should be converted to numeric for further analysis. | Rating: This shows the rating and the possible highest score, which should also be separated out. | . dw_data.head() . vendor category item description price rating . 0 CheapPayTV | Services/Hacking | 12 Month HuluPlus gift Code | 12-Month HuluPlus Codes for $25. They are wort... | 0.05027025666666667 BTC | 4.96/5 | . 1 CheapPayTV | Services/Hacking | Pay TV Sky UK Sky Germany HD TV and much mor... | Hi we offer a World Wide CCcam Service for En... | 0.152419585 BTC | 4.96/5 | . 2 KryptykOG | Services/Hacking | OFFICIAL Account Creator Extreme 4.2 | Tagged Submission Fix Bebo Submission Fix Adju... | 0.007000000000000005 BTC | 4.93/5 | . 3 cyberzen | Services/Hacking | VPN &gt; TOR &gt; SOCK TUTORIAL | How to setup a VPN &gt; TOR &gt; SOCK super safe enc... | 0.019016783532494728 BTC | 4.89/5 | . 4 businessdude | Services/Hacking | Facebook hacking guide | . This guide will teach you how to hack Faceb... | 0.062018073963963936 BTC | 4.88/5 | . From the bitcoin data set, the only relevant variable is column 2, which has been adjusted from 2014 to 2021 USD values and extracted as a single Series. From here, I can obtain the average bitcoin value for 2014 and use it to convert all the listed prices in the Agora data set. This is not a flawless approach as the sale listings do not have specific dates associated with them and Bitcoin varies daily. Therefore, I will also use the lowest and highest Bitcoin values in USD across 2014 to show the possible price ranges. . bitcoin.head() . 0 860.313571 1 899.384815 2 909.776933 3 974.430167 4 1085.770018 Name: Closing Price (USD), dtype: float64 . Cleaning Data . Below is the code that performs the data cleaning discussed above. In addition to all the steps previously outlined, I find price outliers within each category and create a new Boolean column which indicates whether each value is an outlier within its respective category. . In this case, outliers are defined as prices that are above the threshold: . $$price &gt; 1.5 * IQR + 3^{rd} Quartile$$ . where IQR stands for interquartile range. . dw_data = dw_data[dw_data[&#39;price&#39;].str.contains(&#39;BTC&#39;, na=False)] dw_data[&#39;price&#39;] = dw_data[&#39;price&#39;].str.replace(&quot; BTC&quot;, &quot;&quot;) dw_data[&#39;price&#39;] = pd.to_numeric(dw_data[&#39;price&#39;]) # Separating the rating column into rating and total possible score columns dw_data = dw_data[~dw_data[&#39;rating&#39;].str.contains(&#39;[0 deals]&#39;, na=False)] dw_data[&#39;rating&#39;] = dw_data[&#39;rating&#39;].str.replace(&quot;~&quot;, &quot;&quot;) ratings = dw_data[&#39;rating&#39;].str.split(&quot;/&quot;, n=3,expand=True) dw_data[&#39;rating&#39;] = pd.to_numeric(ratings[0]) dw_data[&#39;rating_total&#39;] = pd.to_numeric(ratings[1]) # separating out the categories hierarchy categories = dw_data[&#39;category&#39;].str.split(&quot;/&quot;, n=3,expand=True) categories[0] = categories[0].str.replace(&quot;^Info$&quot;, &quot;Information&quot;) categories_to_use = [&#39;Services&#39;, &#39;Drugs&#39;, &#39;Forgeries&#39;, &#39;Tobacco&#39;, &#39;Counterfeits&#39;, &#39;Data&#39;, &#39;Information&#39;, &#39;Electronics&#39;, &#39;Drug paraphernalia&#39;, &#39;Other&#39;, &#39;Jewelry&#39;, &#39;Weapons&#39;, &#39;Chemicals&#39;] dw_data[&#39;category&#39;] = categories[0] dw_data[&#39;category1&#39;] = categories[1] dw_data[&#39;category2&#39;] = categories[2] dw_data[&#39;category3&#39;] = categories[3] dw_data = dw_data[dw_data[&#39;category&#39;].isin(categories_to_use)].reset_index(drop=True) # converting BTC to 2021 $USD values dw_data[&#39;usd_low&#39;] = np.round(np.min(bitcoin) * dw_data[&#39;price&#39;], 2) dw_data[&#39;usd&#39;] = np.round(np.mean(bitcoin) * dw_data[&#39;price&#39;], 2) dw_data[&#39;usd_high&#39;] = np.round(np.max(bitcoin) * dw_data[&#39;price&#39;], 2) # adding a column that signifies which value is an outlier within top level category def limit(column): iqr = column.quantile(0.75) - column.quantile(0.25) top = column.quantile(0.75) + 1.5*iqr return top limits = dw_data.groupby(&#39;category&#39;)[&#39;usd&#39;].agg(limit) .reset_index().rename(columns={&#39;usd&#39;:&#39;limit&#39;}) dw_data = dw_data.merge(limits, on=&#39;category&#39;, how=&#39;left&#39;) dw_data[&#39;outlier&#39;] = dw_data[&#39;usd&#39;] &gt; dw_data[&#39;limit&#39;] dw_data = dw_data.drop(&#39;limit&#39;, axis=1) # deleting all intermediate data frames del [categories, categories_to_use, ratings, limits] . The resulting data frame is presented below. . print(dw_data.shape) dw_data.head() . (73314, 14) . vendor category item description price rating rating_total category1 category2 category3 usd_low usd usd_high outlier . 0 CheapPayTV | Services | 12 Month HuluPlus gift Code | 12-Month HuluPlus Codes for $25. They are wort... | 0.050270 | 4.96 | 5.0 | Hacking | None | None | 17.23 | 29.60 | 54.58 | False | . 1 CheapPayTV | Services | Pay TV Sky UK Sky Germany HD TV and much mor... | Hi we offer a World Wide CCcam Service for En... | 0.152420 | 4.96 | 5.0 | Hacking | None | None | 52.25 | 89.74 | 165.49 | False | . 2 KryptykOG | Services | OFFICIAL Account Creator Extreme 4.2 | Tagged Submission Fix Bebo Submission Fix Adju... | 0.007000 | 4.93 | 5.0 | Hacking | None | None | 2.40 | 4.12 | 7.60 | False | . 3 cyberzen | Services | VPN &gt; TOR &gt; SOCK TUTORIAL | How to setup a VPN &gt; TOR &gt; SOCK super safe enc... | 0.019017 | 4.89 | 5.0 | Hacking | None | None | 6.52 | 11.20 | 20.65 | False | . 4 businessdude | Services | Facebook hacking guide | . This guide will teach you how to hack Faceb... | 0.062018 | 4.88 | 5.0 | Hacking | None | None | 21.26 | 36.51 | 67.34 | False | . Market Size . Here, I present all the distinct categories that span the hierarchy of all listings on the Agora. For each distinct category, the size represents the total number of items being sold while the two values listed represent the total value of the entire marketplace (category) in 2021 US Dollars. In each graph, there is a top and a bottom Value plot. The top one is simply all the values added up while the bottom one is all the values added up but with the outliers removed. . According to the number of listings and to the entire value of all items listed combined, the marketplace for Drugs on the Agora is the largest one, by far. With over 60,000 listings, and a combined value of over $900 million, it dwarves other categories. . markets = dw_data.groupby(&#39;category&#39;)[&#39;usd&#39;].agg([sum, np.size]).reset_index() .merge(dw_data[~dw_data[&#39;outlier&#39;]] .groupby(&#39;category&#39;)[&#39;usd&#39;] .sum().reset_index(), on=&#39;category&#39;, how=&#39;left&#39;) .rename(columns={&#39;usd&#39;:&#39;sum_no&#39;}) .sort_values(&#39;size&#39;, ascending=False).set_index(&#39;category&#39;) plt.style.use(&quot;dark_background&quot;) fig, ax = plt.subplots(3,1, sharex=True, figsize=(15,10)) ax[0].bar(markets.index, markets[&#39;size&#39;], color = &quot;#BB5566&quot;) ax[0].set_xticklabels(markets.index, rotation=70, size = 15) ax[0].tick_params(axis=&#39;y&#39;, labelsize= 13) ax[0].set_ylabel(&quot;Size&quot;, size = 15) ax[1].bar(markets.index, markets[&#39;sum&#39;], color = &quot;#004488&quot;) ax[1].set_xticklabels(markets.index, rotation=70, size = 15) ax[1].tick_params(axis=&#39;y&#39;, labelsize= 13) ax[1].set_ylabel(&quot;Value (USD)&quot;, size = 15) ax[2].bar(markets.index, markets[&#39;sum_no&#39;], color = &quot;#DDAA33&quot;) ax[2].set_xticklabels(markets.index, rotation=70, size = 15) ax[2].tick_params(axis=&#39;y&#39;, labelsize= 13) ax[2].set_ylabel(&quot;Value (USD)&quot;, size = 15) plt.show() . Given such a pronounced difference between the Drugs marketplace and all the other ones, I created a second version of the plot above, but with the Drugs bar removed. The remaining categories are sorted by the number of listings. The graph at the very bottom is cleared of all outlier effects and shows that Counterfeits and Weapons steadily outpace other categories in the total value of items being sold. . markets_no = markets[markets.index != &#39;Drugs&#39;].sort_values(&#39;size&#39;, ascending=False) plt.style.use(&quot;dark_background&quot;) fig, ax = plt.subplots(3,1, sharex=True, figsize=(15,10)) ax[0].bar(markets_no.index, markets_no[&#39;size&#39;], color = &quot;#BB5566&quot;) ax[0].set_xticklabels(markets_no.index, rotation=70, size = 15) ax[0].tick_params(axis=&#39;y&#39;, labelsize= 13) ax[0].set_ylabel(&quot;Size&quot;, size = 15) ax[1].bar(markets_no.index, markets_no[&#39;sum&#39;], color = &quot;#004488&quot;) ax[1].set_xticklabels(markets_no.index, rotation=70, size = 15) ax[1].tick_params(axis=&#39;y&#39;, labelsize= 13) ax[1].set_ylabel(&quot;Value (USD)&quot;, size = 15) ax[2].bar(markets_no.index, markets_no[&#39;sum_no&#39;], color = &quot;#DDAA33&quot;) ax[2].set_xticklabels(markets_no.index, rotation=70, size = 15) ax[2].tick_params(axis=&#39;y&#39;, labelsize= 13) ax[2].set_ylabel(&quot;Value (USD)&quot;, size = 15) plt.show() . Weapons . weapons_of_interest = [&#39;Glock&#39;, &#39;Ruger&#39;, &#39;Walther&#39;, &#39;Beretta&#39;, &#39;AK-47&#39;] weapons_df = pd.DataFrame(columns=[&#39;item&#39;, &#39;price&#39;, &#39;usd&#39;]) for i in range(5): subset = dw_data[dw_data[&#39;category1&#39;] == &#39;Lethal firearms&#39;] subset = subset[subset[&#39;item&#39;].str.contains(weapons_of_interest[i], na=False)] weapons_df = weapons_df.append(subset[weapons_df.columns], ignore_index=True) weapons_df[&#39;weapon&#39;] = &#39;weapon&#39; for i in range(5): weapons_df.loc[:, &#39;weapon&#39;][weapons_df[&#39;item&#39;] .str.contains(weapons_of_interest[i], na=False)] = weapons_of_interest[i] weapons_df = weapons_df.reset_index(drop=True) del [subset, i, weapons_of_interest] print(weapons_df.shape) weapons_df.head() . (67, 4) . item price usd weapon . 0 Glock 19 Gen 3 9mm &amp; 2 Mags | 4.862971 | 2863.12 | Glock | . 1 Glock 17 3rd Gen FULL ESCROW | 3.656912 | 2153.04 | Glock | . 2 Glock 21SF 45 ACP FULL ESCROW | 3.656912 | 2153.04 | Glock | . 3 Glock 20 10MM FULL ESCROW | 3.656912 | 2153.04 | Glock | . 4 Glock 26 gen 3 9mm &amp; 2 mags | 4.598510 | 2707.41 | Glock | . Here, I create a data frame listing all the popular weapons brands, most of which can be found in the US legally. The names were extracted from the item descriptions and median prices were obtained for each brand. . weapons = weapons_df.groupby(&#39;weapon&#39;)[&#39;usd&#39;].median() .reset_index().sort_values(&#39;usd&#39;) .set_index(&#39;weapon&#39;) plt.style.use(&quot;dark_background&quot;) fig, ax = plt.subplots(figsize=(13,10)) ax.bar(weapons.index, weapons[&#39;usd&#39;], color = &#39;#004488&#39;) ax.set_xticklabels(weapons.index, size = 20) ax.tick_params(axis=&#39;y&#39;, labelsize= 15) ax.set_ylabel(&quot;Median Cost (USD)&quot;, size = 25) plt.show() . Buying weapons illegaly, compared to the usual US prices, is significantly more expensive. The median price for each brand listen on the Agora is anywhere between two to five times more expensive than if purchased from an accredited weapons dealer. Further analysis would be interesting here to determine the specific difference between legal prices and the ones from the Dark Web. Currently, that is beyond the scope of this project. . Drugs . drugs = dw_data[dw_data[&#39;category&#39;]==&#39;Drugs&#39;].groupby(&#39;category1&#39;)[&#39;usd&#39;] .agg([sum, np.size]).reset_index().sort_values(&#39;size&#39;, ascending=False) .set_index(&#39;category1&#39;) print(drugs.shape) drugs.head() . (13, 2) . sum size . category1 . Cannabis 5.200670e+08 | 20542.0 | . Ecstasy 1.700251e+08 | 9654.0 | . Stimulants 1.852040e+08 | 8474.0 | . Psychedelics 9.215761e+06 | 5384.0 | . Opioids 7.974575e+06 | 4474.0 | . plt.style.use(&quot;dark_background&quot;) fig, ax = plt.subplots(2, 1, sharex=True, figsize=(15,10)) ax[0].bar(drugs.index, drugs[&#39;size&#39;], color = &#39;#BB5566&#39;) ax[0].set_xticklabels(drugs.index, rotation=70, size = 20) ax[0].tick_params(axis=&#39;y&#39;, labelsize= 15) ax[0].set_ylabel(&quot;Size&quot;, size = 20) ax[1].bar(drugs.index, drugs[&#39;sum&#39;], color = &#39;#004488&#39;) ax[1].set_ylabel(&quot;Value (USD)&quot;, size = 20) ax[1].set_xticklabels(drugs.index, rotation=70, size = 20) ax[1].tick_params(axis=&#39;y&#39;, labelsize= 15) plt.show() . As pictured above, cannabis sales are much higher than those from all the other types of drugs sold on the Agora. Both in total market value (over $500 million) and market size (over 20,000 listings), illegal cannabis sales (at least in 2014) were far more popular than those of any other type of drug. . YouTube . social_media_regex = [&#39;[Y|y][O|o][U|u][T|t][U|u][B|b][E|e]&#39;, &#39;[T|t][W|w][I|i][T|t][T|t][E|e][R|r]&#39;, &#39;[F|f][A|a][C|c][E|e][B|b][O|o][O|o][K|k]&#39;, &#39;[I|i][N|n][S|s][T|t][A|a][G|g][R|r][A|a][M|m]&#39;] social_media = [&#39;YouTube&#39;, &#39;Twitter&#39;, &#39;Facebook&#39;, &#39;Instagram&#39;] products_regex = [&#39;[L|l][I|i][K|k][E|e]&#39;, &#39;[S|s][U|u][B|b][S|s][C|c][R|r][I|i][B|b][E|e][R|r]&#39;, &#39;[V|v][I|i][E|e][W|w]&#39;, &#39;[C|c][O|o][M|m][M|m][E|e][N|n][T|t]&#39;] products = [&#39;likes&#39;, &#39;subscribers&#39;, &#39;views&#39;, &#39;comments&#39;] social_media_df = pd.DataFrame(columns=[&#39;item&#39;, &#39;price&#39;, &#39;usd&#39;]) for i in range(4): subset = dw_data[dw_data[&#39;category1&#39;] == &#39;Advertising&#39;] subset = subset[subset[&#39;item&#39;].str.contains(social_media_regex[i], na=False)] social_media_df = social_media_df.append(subset[social_media_df.columns], ignore_index=True) social_media_df[&#39;company&#39;] = &#39;company&#39; social_media_df[&#39;product&#39;] = &#39;product&#39; for i in range(4): social_media_df.loc[:, &#39;company&#39;][social_media_df[&#39;item&#39;] .str.contains(social_media_regex[i], na=False)] = social_media[i] social_media_df.loc[:, &#39;product&#39;][social_media_df[&#39;item&#39;] .str.contains(products_regex[i], na=False)] = products[i] social_media_df = social_media_df[social_media_df[&#39;product&#39;] != &#39;product&#39;] .reset_index(drop=True) quantity = social_media_df[&#39;item&#39;] .str.extract(&#39;( d[ s| d]? d? d? s? d? d? d? s? d? d? d?)&#39;, expand=False).str.replace(&#39; s&#39;, &quot;&quot;) social_media_df[&#39;quantity&#39;] = pd.to_numeric(quantity) social_media_df.loc[64, &#39;quantity&#39;] = 5000 social_media_df[&#39;unit_price&#39;] = social_media_df[&#39;price&#39;] / social_media_df[&#39;quantity&#39;] social_media_df[&#39;unit_usd&#39;] = social_media_df[&#39;usd&#39;] / social_media_df[&#39;quantity&#39;] del [social_media_regex, social_media, products_regex, products, subset, i, quantity] print(social_media_df.shape) social_media_df.head() . (74, 8) . item price usd company product quantity unit_price unit_usd . 0 100 Youtube likes just 8 USD! | 0.032760 | 19.29 | YouTube | likes | 100 | 0.000328 | 0.192900 | . 1 100 Youtube subscriber just 10 USD! | 0.040950 | 24.11 | YouTube | subscribers | 100 | 0.000409 | 0.241100 | . 2 100 Youtube unlike just 10 USD! | 0.040929 | 24.10 | YouTube | likes | 100 | 0.000409 | 0.241000 | . 3 1000 Youtube views just 10 USD | 0.040960 | 24.12 | YouTube | views | 1000 | 0.000041 | 0.024120 | . 4 500 000 Real High Retention Youtube views | 2.747742 | 1617.76 | YouTube | views | 500000 | 0.000005 | 0.003236 | . Gathering social media content into a coherent data frame was a little more work. The code above extracts the per unit cost in purchasing an additional like, subscriber, view or comment for a given social media account. Most listings are regarding Facebook and Youtube. The code above uses the item descriptions to extract the number and type of unit being sold, and creates several new columns that reflect this while facilitating further analysis. . youtube = social_media_df[social_media_df[&#39;company&#39;]==&#39;YouTube&#39;] .groupby(&#39;product&#39;)[&#39;unit_usd&#39;].median().reset_index() .sort_values(&#39;unit_usd&#39;, ascending=False).set_index(&#39;product&#39;) plt.style.use(&quot;dark_background&quot;) fig, ax = plt.subplots(figsize=(15,10)) ax.bar(youtube.index, youtube[&#39;unit_usd&#39;], color = &#39;#228833&#39;) ax.set_xticklabels(youtube.index, size = 20) ax.tick_params(axis=&#39;y&#39;, labelsize= 15) ax.set_ylabel(&quot;Median Cost per Unit (USD)&quot;, size = 20) plt.show() . Pictured above, is the data for YouTube. According to all the postings, each additional comment was worth around 60 cents of a 2021 USD, putting it higher than subscribers, likes or views. Vast majority of these listings indicate that each product is of &#39;high quality&#39; meaning they are such that bot detecting software would not cleanse them. This usually indicates click farms (mostly from third world countries in which people are paid to constantly create new accounts and provide social media engagement) but such a claim cannot be ascertained from given data alone. . Below, I quickly calculate the expected per-unit-cost of a Facebook like, which seems to be a somewhat lower value than YouTube likes. . fb_like = social_media_df[(social_media_df[&#39;company&#39;]==&#39;Facebook&#39;) &amp; (social_media_df[&#39;product&#39;]==&#39;likes&#39;)] .loc[:, &#39;unit_usd&#39;].median() print(&quot;The expected per-unit cost of a Facebook like is&quot;, round(fb_like*100, 2), &quot;cents (2021 $USD).&quot;) . The expected per-unit cost of a Facebook like is 12.48 cents (2021 $USD). . Documents . doc_regex = [&#39;[P|p]assport&#39;, &#39;[D|d]river[ &#39;]?s[ s]?&#39;] doc = [&quot;Passport&quot;, &quot;Driver&#39;s License&quot;] docs_df = pd.DataFrame(columns=[&#39;item&#39;, &#39;price&#39;, &#39;usd&#39;]) for i in range(2): subset = dw_data[dw_data[&#39;category1&#39;] == &#39;Physical documents&#39;] subset = subset[subset[&#39;item&#39;].str.contains(doc_regex[i], na=False)] docs_df = docs_df.append(subset[docs_df.columns], ignore_index=True) docs_df[&#39;document&#39;] = &#39;document&#39; for i in range(2): docs_df.loc[:, &#39;document&#39;][docs_df[&#39;item&#39;] .str.contains(doc_regex[i], na=False)] = doc[i] docs_df.loc[:, &#39;document&#39;][docs_df[&#39;item&#39;] .str.contains(&#39;Passport[ s]?[+]&#39;)] = &quot;Passport+ID+Driver&#39;s License&quot; docs_df = docs_df[~docs_df[&#39;item&#39;].str.contains(&#39;emplate&#39;)].reset_index(drop=True) del [doc, doc_regex, i, subset] print(docs_df.shape) docs_df.head() . (114, 4) . item price usd document . 0 Fake Danish Passport | 2.808987 | 1653.82 | Passport | . 1 Fake Lithuanian Passport (old version) | 3.803150 | 2239.14 | Passport | . 2 Fake Lithuanian Passport | 2.475635 | 1457.55 | Passport | . 3 Netherlands Physical Passport + DL + ID CARD | 7.761003 | 4569.36 | Passport+ID+Driver&#39;s License | . 4 Pysical Fake Passports and IDs | 0.015551 | 9.16 | Passport | . This data frame was created in a way similar to the social media one. Item descriptions were used to separate out the type of &#39;product&#39; being sold. Three specific groups were identified: Passports, Driver&#39;s Licenses and a combination product of Passport, ID and Driver&#39;s License. These are worldwide so documents belong to numerous countries and/or states. For the sake of simplicity, the median cost is calculated on a worldwide basis. Counterfeit document listing also include a lot of templates being sold, which were filtered out, given that their values were significantly lower. . documents = docs_df.groupby(&#39;document&#39;)[&#39;usd&#39;].median().reset_index() .sort_values(&#39;usd&#39;, ascending=False).set_index(&#39;document&#39;) plt.style.use(&quot;dark_background&quot;) fig, ax = plt.subplots(figsize=(15,10)) ax.bar(documents.index, documents[&#39;usd&#39;], color = &#39;#AA3377&#39;) ax.set_xticklabels(documents.index, size = 15) ax.set_ylabel(&quot;Median Cost (USD)&quot;, size = 20) ax.tick_params(axis=&#39;y&#39;, labelsize= 15) plt.show() . Median costs were calcualted given that there are numerous countries listed, with varying degrees of value associated with their documentation, as well as several prominent outliers. While this category provides listings for real documents, that is, documents that are actually harder to detect as illegaly obtained and that exist in some database, there are many from the Fake category that slip into this one. They usually cost much less but the wording in the item description is difficult to use in filtering them out. Hopefully, the median expectation protects against these outlier effects. . Cigarettes . cigs_regex = [&#39;[D|d][U|u][N|n][H|h][I|i][L|l][L|l]&#39;, &#39;[B|b][O|o][N|n][D|d]&#39;, &#39;[V|v][O|o][G|g][U|u][E|e]&#39;, &#39;[W|w][I|i][N|n][S|s][T|t][O|o][N|n]&#39;, &#39;[M|m][A|a][R|r][L|l][B|b][O|o][R|r][O|o]&#39;, &#39;[P|p][A|a][L|l][L|l][ s]?[M|m][A|a][L|l][L|l]&#39;, &#39;[L|l][ s]?[&amp;][ s]?[M|m]&#39;, &#39;[L|l][U|u][C|c][K|k][Y|y]&#39;, &#39;[C|c][A|a][M|m][E|e][L|l]&#39;, &#39;[C|c][H|h][E|e][S|s][T|t][E|e][R|r]&#39;, &#39;[D|d][A|a][V|v][I|i][D|d][O|o]&#39;, &#39;[P|p][A|a][R|r][L|l][I|i][A|a][M|m]&#39;, &#39;[V|v][I|i][R|r][G|g][I|i][N|n][I|i][A|a]&#39;, &#39;[R|r][E|e][D|d][ s]?[&amp;][ s]?[W|w][H|h][I|i][T|t][E|e]&#39;] cigs = [&#39;Dunhill&#39;, &#39;Bond&#39;, &#39;Vogue&#39;, &#39;Winston&#39;, &#39;Marlboro&#39;, &#39;Pall Mall&#39;, &#39;L&amp;M&#39;, &#39;Lucky Strike&#39;, &#39;Camel&#39;, &#39;Chesterfield&#39;, &#39;Davidoff&#39;, &#39;Parliament&#39;, &#39;Virginia&#39;, &#39;Red&amp;White&#39;] cigs_df = pd.DataFrame(columns=[&#39;item&#39;, &#39;price&#39;, &#39;usd&#39;]) for i in range(10): subset = dw_data[dw_data[&#39;category1&#39;] == &#39;Smoked&#39;] subset = subset[subset[&#39;item&#39;].str.contains(cigs_regex[i], na=False)] cigs_df = cigs_df.append(subset[cigs_df.columns], ignore_index=True) cigs_df[&#39;brand&#39;] = &#39;brand&#39; for i in range(14): cigs_df.loc[:, &#39;brand&#39;][cigs_df[&#39;item&#39;] .str.contains(cigs_regex[i], na=False)] = cigs[i] # almost all original prices are listed for 10 packs, so I divide by 10 to get pack price # but sometimes it&#39;s a single pack listed and that&#39;s why I did this division only when # the total price listed was above 10USD cigs_df[&#39;unit_cost&#39;] = cigs_df[&#39;usd&#39;] cigs_df.loc[:, &#39;unit_cost&#39;][cigs_df[&#39;unit_cost&#39;] &gt; 10] = cigs_df[&#39;unit_cost&#39;] / 10 cigs_df = cigs_df.reset_index(drop=True) del [cigs_regex, cigs, subset, i] print(cigs_df.shape) cigs_df.head() . (101, 5) . item price usd brand unit_cost . 0 Dunhill Fine Cut Dark Blue (10 packs x 20 ciga... | 0.160849 | 94.70 | Dunhill | 9.470 | . 1 DUNHILL Cheap Cigarettes to USA and EU | 0.156015 | 91.86 | Dunhill | 9.186 | . 2 Dunhill Fine Cut Black (10 packs x 20 cigarettes) | 0.160806 | 94.68 | Dunhill | 9.468 | . 3 Copy of Dunhill Fine Cut Black (10 packs x 20 ... | 0.091288 | 53.75 | Dunhill | 5.375 | . 4 Bond Cheap Cigarettes to USA and EU | 0.088071 | 51.85 | Bond | 5.185 | . Again, repeating the procedure used for the social media and documentation data frames, once again I go through the item descriptions and extract all the relevant cigarette brands to group by later. Furthermore, it is clear from the description that almost every single listed price is for a product consisting of 10 packs with 20 cigarettes each. Therefore, the Bitcoin price was converted to US Dollar values, and divided by 10, to get the cost of a single pack for each brand. . cigarettes = cigs_df.groupby(&#39;brand&#39;)[&#39;unit_cost&#39;].median().reset_index() .sort_values(&#39;unit_cost&#39;, ascending=False).set_index(&#39;brand&#39;) plt.style.use(&quot;dark_background&quot;) fig, ax = plt.subplots(figsize=(15,10)) ax.bar(cigarettes.index, cigarettes[&#39;unit_cost&#39;], color = &#39;#CC3311&#39;) ax.set_xticklabels(cigarettes.index, rotation=80, size = 20) ax.set_ylabel(&quot;Median Cost per Pack (USD)&quot;, size = 20) ax.tick_params(axis=&#39;y&#39;, labelsize= 15) plt.show() . As can be seen in the plot above, the brands are sorted by cost. The prices are median costs, per pack, in 2021 $USD. Surprisingly, they don&#39;t differ significantly from prices in states with low to moderate taxes. However, they are much smaller than those in states like New York, which have costs of around $15 per pack, easily. . Conclusion . As an initial look into the illegal dealings on the Dark Web, this project is appropriate. It allows for a preliminary sense of how products are listed, what the scope of the markets is, how data is organized and what possible insights can be gleaned from it. Furthermore, it illuminates all the issues present in trying to make sense of it all. The prices are listed in Bitcoin and held online for unknown periods of time, even as Bitcoin fluctuates. Knowing the possible range for a year helps in narrowing down the expected cost values. However, error bars need to be created to show the amount of uncertainty in this approach. . With more computing power and detailed string parsing scripts, I would be willing to take a crack at the 1.6TB data set. Price differences between legal and illegal products can illuminate countless premiums customers are willing to pay on various products, which is a worthwhile endeavor for any economist to pursue. . For the data and other notebooks, see github.com/antoniojurlina/learning_python. .",
            "url": "https://antoniojurlina.github.io/portfolio/2021/05/07/Dark_Web.html",
            "relUrl": "/2021/05/07/Dark_Web.html",
            "date": " • May 7, 2021"
        }
        
    
  

  
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page9": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://antoniojurlina.github.io/portfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}