{
  
    
        "post0": {
            "title": "Title",
            "content": "Agora - A Dark Web Marketplace . Data analysis and visualization . Antonio Jurlina . import pandas as pd import numpy as np import matplotlib.pyplot as plt import os import warnings warnings.filterwarnings(&quot;ignore&quot;) os.chdir(&#39;/Users/antoniojurlina/Projects/learning_python/data/&#39;) . A few years ago, a reddit user called usheep scraped a DarkWeb marketplace called the Agora for a list of vendors, their identities and products, while threatening to expose them all as blackmail. Eventually, this data set made it to the general public, and while usheep disappeared, we have thousands of rows of vendors, items, categories, descriptions and prices in an organized data set that contains drugs, weapons, books, services, and more. There are over 100,000 unique observations spanning year 2014. My goal is to analyze this data set and explore some common items being sold, as well as the usual prices across categories. . Although there is over 1.6TB of uncompressed, scraped data of dark web sales available out there, the goal of this project will be to look at the Kaggle published subset which is around 30MB and contains ~100,000 observations. The data set is available as a direct .csv download with a Kaggle account. Additonally, since all the prices listed in this data set are in Bitcoin, I went to Coindesk and downloaded the daily closing price of Bitcoin in US Dollar amounts, for that whole period. This data set will be used to make the costs more comprehensible by converting them to current USD prices. . dw_data = pd.read_csv(&quot;Agora.csv&quot;, usecols=[&#39;Vendor&#39;, &#39; Category&#39;, &#39; Item&#39;, &#39; Item Description&#39;, &#39; Price&#39;, &#39; Rating&#39;]) .rename(columns={&#39;Vendor&#39;:&#39;vendor&#39;, &#39; Category&#39;:&#39;category&#39;, &#39; Item&#39;:&#39;item&#39;, &#39; Item Description&#39;:&#39;description&#39;, &#39; Price&#39;:&#39;price&#39;, &#39; Rating&#39;:&#39;rating&#39;}) # Importing Bitcoin data and selecting out the relevant column bitcoin = pd.read_csv(&quot;BTC_USD_2014-01-02_2015-01-01-CoinDesk.csv&quot;) inflation = 0.1186 # the inflation rate between 2014 and 2021 bitcoin = bitcoin.iloc[:,2]*(1+inflation) . The Agora data set sample, as it is currently in the memory, is shown below. The variables that need to be cleaned up further are category, price, and rating. . Category: There are categories and subcategories within this column that need to be split into separate columns. | Price: This a string because the word BTC is present in each and should be converted to numeric for further analysis. | Rating: This shows the rating and the possible highest score, which should also be separated out. | . dw_data.head() . vendor category item description price rating . 0 CheapPayTV | Services/Hacking | 12 Month HuluPlus gift Code | 12-Month HuluPlus Codes for $25. They are wort... | 0.05027025666666667 BTC | 4.96/5 | . 1 CheapPayTV | Services/Hacking | Pay TV Sky UK Sky Germany HD TV and much mor... | Hi we offer a World Wide CCcam Service for En... | 0.152419585 BTC | 4.96/5 | . 2 KryptykOG | Services/Hacking | OFFICIAL Account Creator Extreme 4.2 | Tagged Submission Fix Bebo Submission Fix Adju... | 0.007000000000000005 BTC | 4.93/5 | . 3 cyberzen | Services/Hacking | VPN &gt; TOR &gt; SOCK TUTORIAL | How to setup a VPN &gt; TOR &gt; SOCK super safe enc... | 0.019016783532494728 BTC | 4.89/5 | . 4 businessdude | Services/Hacking | Facebook hacking guide | . This guide will teach you how to hack Faceb... | 0.062018073963963936 BTC | 4.88/5 | . From the bitcoin data set, the only relevant variable is column 2, which has been adjusted from 2014 to 2021 USD values and extracted as a single Series. From here, I can obtain the average bitcoin value for 2014 and use it to convert all the listed prices in the Agora data set. This is not a flawless approach as the sale listings do not have specific dates associated with them and Bitcoin varies daily. Therefore, I will also use the lowest and highest Bitcoin values in USD across 2014 to show the possible price ranges. . bitcoin.head() . 0 860.313571 1 899.384815 2 909.776933 3 974.430167 4 1085.770018 Name: Closing Price (USD), dtype: float64 . Cleaning Data . Below is the code that performs the data cleaning discussed above. In addition to all the steps previously outlined, I find price outliers within each category and create a new Boolean column which indicates whether each value is an outlier within its respective category. . In this case, outliers are defined as prices that are above the threshold: . $$price &gt; 1.5 * IQR + 3^{rd} Quartile$$ . where IQR stands for interquartile range. . dw_data = dw_data[dw_data[&#39;price&#39;].str.contains(&#39;BTC&#39;, na=False)] dw_data[&#39;price&#39;] = dw_data[&#39;price&#39;].str.replace(&quot; BTC&quot;, &quot;&quot;) dw_data[&#39;price&#39;] = pd.to_numeric(dw_data[&#39;price&#39;]) # Separating the rating column into rating and total possible score columns dw_data = dw_data[~dw_data[&#39;rating&#39;].str.contains(&#39;[0 deals]&#39;, na=False)] dw_data[&#39;rating&#39;] = dw_data[&#39;rating&#39;].str.replace(&quot;~&quot;, &quot;&quot;) ratings = dw_data[&#39;rating&#39;].str.split(&quot;/&quot;, n=3,expand=True) dw_data[&#39;rating&#39;] = pd.to_numeric(ratings[0]) dw_data[&#39;rating_total&#39;] = pd.to_numeric(ratings[1]) # separating out the categories hierarchy categories = dw_data[&#39;category&#39;].str.split(&quot;/&quot;, n=3,expand=True) categories[0] = categories[0].str.replace(&quot;^Info$&quot;, &quot;Information&quot;) categories_to_use = [&#39;Services&#39;, &#39;Drugs&#39;, &#39;Forgeries&#39;, &#39;Tobacco&#39;, &#39;Counterfeits&#39;, &#39;Data&#39;, &#39;Information&#39;, &#39;Electronics&#39;, &#39;Drug paraphernalia&#39;, &#39;Other&#39;, &#39;Jewelry&#39;, &#39;Weapons&#39;, &#39;Chemicals&#39;] dw_data[&#39;category&#39;] = categories[0] dw_data[&#39;category1&#39;] = categories[1] dw_data[&#39;category2&#39;] = categories[2] dw_data[&#39;category3&#39;] = categories[3] dw_data = dw_data[dw_data[&#39;category&#39;].isin(categories_to_use)].reset_index(drop=True) # converting BTC to 2021 $USD values dw_data[&#39;usd_low&#39;] = np.round(np.min(bitcoin) * dw_data[&#39;price&#39;], 2) dw_data[&#39;usd&#39;] = np.round(np.mean(bitcoin) * dw_data[&#39;price&#39;], 2) dw_data[&#39;usd_high&#39;] = np.round(np.max(bitcoin) * dw_data[&#39;price&#39;], 2) # adding a column that signifies which value is an outlier within top level category def limit(column): iqr = column.quantile(0.75) - column.quantile(0.25) top = column.quantile(0.75) + 1.5*iqr return top limits = dw_data.groupby(&#39;category&#39;)[&#39;usd&#39;].agg(limit) .reset_index().rename(columns={&#39;usd&#39;:&#39;limit&#39;}) dw_data = dw_data.merge(limits, on=&#39;category&#39;, how=&#39;left&#39;) dw_data[&#39;outlier&#39;] = dw_data[&#39;usd&#39;] &gt; dw_data[&#39;limit&#39;] dw_data = dw_data.drop(&#39;limit&#39;, axis=1) # deleting all intermediate data frames del [categories, categories_to_use, ratings, limits] . The resulting data frame is presented below. . print(dw_data.shape) dw_data.head() . (73314, 14) . vendor category item description price rating rating_total category1 category2 category3 usd_low usd usd_high outlier . 0 CheapPayTV | Services | 12 Month HuluPlus gift Code | 12-Month HuluPlus Codes for $25. They are wort... | 0.050270 | 4.96 | 5.0 | Hacking | None | None | 17.23 | 29.60 | 54.58 | False | . 1 CheapPayTV | Services | Pay TV Sky UK Sky Germany HD TV and much mor... | Hi we offer a World Wide CCcam Service for En... | 0.152420 | 4.96 | 5.0 | Hacking | None | None | 52.25 | 89.74 | 165.49 | False | . 2 KryptykOG | Services | OFFICIAL Account Creator Extreme 4.2 | Tagged Submission Fix Bebo Submission Fix Adju... | 0.007000 | 4.93 | 5.0 | Hacking | None | None | 2.40 | 4.12 | 7.60 | False | . 3 cyberzen | Services | VPN &gt; TOR &gt; SOCK TUTORIAL | How to setup a VPN &gt; TOR &gt; SOCK super safe enc... | 0.019017 | 4.89 | 5.0 | Hacking | None | None | 6.52 | 11.20 | 20.65 | False | . 4 businessdude | Services | Facebook hacking guide | . This guide will teach you how to hack Faceb... | 0.062018 | 4.88 | 5.0 | Hacking | None | None | 21.26 | 36.51 | 67.34 | False | . Market Size . Here, I present all the distinct categories that span the hierarchy of all listings on the Agora. For each distinct category, the size represents the total number of items being sold while the two values listed represent the total value of the entire marketplace (category) in 2021 US Dollars. In each graph, there is a top and a bottom Value plot. The top one is simply all the values added up while the bottom one is all the values added up but with the outliers removed. . According to the number of listings and to the entire value of all items listed combined, the marketplace for Drugs on the Agora is the largest one, by far. With over 60,000 listings, and a combined value of over $900 million, it dwarves other categories. . markets = dw_data.groupby(&#39;category&#39;)[&#39;usd&#39;].agg([sum, np.size]).reset_index() .merge(dw_data[~dw_data[&#39;outlier&#39;]] .groupby(&#39;category&#39;)[&#39;usd&#39;] .sum().reset_index(), on=&#39;category&#39;, how=&#39;left&#39;) .rename(columns={&#39;usd&#39;:&#39;sum_no&#39;}) .sort_values(&#39;size&#39;, ascending=False).set_index(&#39;category&#39;) plt.style.use(&quot;seaborn-whitegrid&quot;) fig, ax = plt.subplots(3,1, sharex=True, figsize=(15,10)) ax[0].bar(markets.index, markets[&#39;size&#39;], color = &quot;#BB5566&quot;) ax[0].set_xticklabels(markets.index, rotation=70, size = 15) ax[0].tick_params(axis=&#39;y&#39;, labelsize= 13) ax[0].set_ylabel(&quot;Size&quot;, size = 15) ax[1].bar(markets.index, markets[&#39;sum&#39;], color = &quot;#004488&quot;) ax[1].set_xticklabels(markets.index, rotation=70, size = 15) ax[1].tick_params(axis=&#39;y&#39;, labelsize= 13) ax[1].set_ylabel(&quot;Value (USD)&quot;, size = 15) ax[2].bar(markets.index, markets[&#39;sum_no&#39;], color = &quot;#DDAA33&quot;) ax[2].set_xticklabels(markets.index, rotation=70, size = 15) ax[2].tick_params(axis=&#39;y&#39;, labelsize= 13) ax[2].set_ylabel(&quot;Value (USD)&quot;, size = 15) plt.show() . Given such a pronounced difference between the Drugs marketplace and all the other ones, I created a second version of the plot above, but with the Drugs bar removed. The remaining categories are sorted by the number of listings. The graph at the very bottom is cleared of all outlier effects and shows that Counterfeits and Weapons steadily outpace other categories in the total value of items being sold. . markets_no = markets[markets.index != &#39;Drugs&#39;].sort_values(&#39;size&#39;, ascending=False) plt.style.use(&quot;seaborn-whitegrid&quot;) fig, ax = plt.subplots(3,1, sharex=True, figsize=(15,10)) ax[0].bar(markets_no.index, markets_no[&#39;size&#39;], color = &quot;#BB5566&quot;) ax[0].set_xticklabels(markets_no.index, rotation=70, size = 15) ax[0].tick_params(axis=&#39;y&#39;, labelsize= 13) ax[0].set_ylabel(&quot;Size&quot;, size = 15) ax[1].bar(markets_no.index, markets_no[&#39;sum&#39;], color = &quot;#004488&quot;) ax[1].set_xticklabels(markets_no.index, rotation=70, size = 15) ax[1].tick_params(axis=&#39;y&#39;, labelsize= 13) ax[1].set_ylabel(&quot;Value (USD)&quot;, size = 15) ax[2].bar(markets_no.index, markets_no[&#39;sum_no&#39;], color = &quot;#DDAA33&quot;) ax[2].set_xticklabels(markets_no.index, rotation=70, size = 15) ax[2].tick_params(axis=&#39;y&#39;, labelsize= 13) ax[2].set_ylabel(&quot;Value (USD)&quot;, size = 15) plt.show() . Weapons . weapons_of_interest = [&#39;Glock&#39;, &#39;Ruger&#39;, &#39;Walther&#39;, &#39;Beretta&#39;, &#39;AK-47&#39;] weapons_df = pd.DataFrame(columns=[&#39;item&#39;, &#39;price&#39;, &#39;usd&#39;]) for i in range(5): subset = dw_data[dw_data[&#39;category1&#39;] == &#39;Lethal firearms&#39;] subset = subset[subset[&#39;item&#39;].str.contains(weapons_of_interest[i], na=False)] weapons_df = weapons_df.append(subset[weapons_df.columns], ignore_index=True) weapons_df[&#39;weapon&#39;] = &#39;weapon&#39; for i in range(5): weapons_df.loc[:, &#39;weapon&#39;][weapons_df[&#39;item&#39;] .str.contains(weapons_of_interest[i], na=False)] = weapons_of_interest[i] weapons_df = weapons_df.reset_index(drop=True) del [subset, i, weapons_of_interest] print(weapons_df.shape) weapons_df.head() . (67, 4) . item price usd weapon . 0 Glock 19 Gen 3 9mm &amp; 2 Mags | 4.862971 | 2863.12 | Glock | . 1 Glock 17 3rd Gen FULL ESCROW | 3.656912 | 2153.04 | Glock | . 2 Glock 21SF 45 ACP FULL ESCROW | 3.656912 | 2153.04 | Glock | . 3 Glock 20 10MM FULL ESCROW | 3.656912 | 2153.04 | Glock | . 4 Glock 26 gen 3 9mm &amp; 2 mags | 4.598510 | 2707.41 | Glock | . Here, I create a data frame listing all the popular weapons brands, most of which can be found in the US legally. The names were extracted from the item descriptions and median prices were obtained for each brand. . weapons = weapons_df.groupby(&#39;weapon&#39;)[&#39;usd&#39;].median() .reset_index().sort_values(&#39;usd&#39;) .set_index(&#39;weapon&#39;) plt.style.use(&quot;seaborn-whitegrid&quot;) fig, ax = plt.subplots(figsize=(13,10)) ax.bar(weapons.index, weapons[&#39;usd&#39;], color = &#39;#004488&#39;) ax.set_xticklabels(weapons.index, size = 20) ax.tick_params(axis=&#39;y&#39;, labelsize= 15) ax.set_ylabel(&quot;Median Cost (USD)&quot;, size = 25) plt.show() . Buying weapons illegaly, compared to the usual US prices, is significantly more expensive. The median price for each brand listen on the Agora is anywhere between two to five times more expensive than if purchased from an accredited weapons dealer. Further analysis would be interesting here to determine the specific difference between legal prices and the ones from the Dark Web. Currently, that is beyond the scope of this project. . Drugs . drugs = dw_data[dw_data[&#39;category&#39;]==&#39;Drugs&#39;].groupby(&#39;category1&#39;)[&#39;usd&#39;] .agg([sum, np.size]).reset_index().sort_values(&#39;size&#39;, ascending=False) .set_index(&#39;category1&#39;) print(drugs.shape) drugs.head() . (13, 2) . sum size . category1 . Cannabis 5.200670e+08 | 20542.0 | . Ecstasy 1.700251e+08 | 9654.0 | . Stimulants 1.852040e+08 | 8474.0 | . Psychedelics 9.215761e+06 | 5384.0 | . Opioids 7.974575e+06 | 4474.0 | . plt.style.use(&quot;seaborn-whitegrid&quot;) fig, ax = plt.subplots(2, 1, sharex=True, figsize=(15,10)) ax[0].bar(drugs.index, drugs[&#39;size&#39;], color = &#39;#BB5566&#39;) ax[0].set_xticklabels(drugs.index, rotation=70, size = 20) ax[0].tick_params(axis=&#39;y&#39;, labelsize= 15) ax[0].set_ylabel(&quot;Size&quot;, size = 20) ax[1].bar(drugs.index, drugs[&#39;sum&#39;], color = &#39;#004488&#39;) ax[1].set_ylabel(&quot;Value (USD)&quot;, size = 20) ax[1].set_xticklabels(drugs.index, rotation=70, size = 20) ax[1].tick_params(axis=&#39;y&#39;, labelsize= 15) plt.show() . As pictured above, cannabis sales are much higher than those from all the other types of drugs sold on the Agora. Both in total market value (over $500 million) and market size (over 20,000 listings), illegal cannabis sales (at least in 2014) were far more popular than those of any other type of drug. . YouTube . social_media_regex = [&#39;[Y|y][O|o][U|u][T|t][U|u][B|b][E|e]&#39;, &#39;[T|t][W|w][I|i][T|t][T|t][E|e][R|r]&#39;, &#39;[F|f][A|a][C|c][E|e][B|b][O|o][O|o][K|k]&#39;, &#39;[I|i][N|n][S|s][T|t][A|a][G|g][R|r][A|a][M|m]&#39;] social_media = [&#39;YouTube&#39;, &#39;Twitter&#39;, &#39;Facebook&#39;, &#39;Instagram&#39;] products_regex = [&#39;[L|l][I|i][K|k][E|e]&#39;, &#39;[S|s][U|u][B|b][S|s][C|c][R|r][I|i][B|b][E|e][R|r]&#39;, &#39;[V|v][I|i][E|e][W|w]&#39;, &#39;[C|c][O|o][M|m][M|m][E|e][N|n][T|t]&#39;] products = [&#39;likes&#39;, &#39;subscribers&#39;, &#39;views&#39;, &#39;comments&#39;] social_media_df = pd.DataFrame(columns=[&#39;item&#39;, &#39;price&#39;, &#39;usd&#39;]) for i in range(4): subset = dw_data[dw_data[&#39;category1&#39;] == &#39;Advertising&#39;] subset = subset[subset[&#39;item&#39;].str.contains(social_media_regex[i], na=False)] social_media_df = social_media_df.append(subset[social_media_df.columns], ignore_index=True) social_media_df[&#39;company&#39;] = &#39;company&#39; social_media_df[&#39;product&#39;] = &#39;product&#39; for i in range(4): social_media_df.loc[:, &#39;company&#39;][social_media_df[&#39;item&#39;] .str.contains(social_media_regex[i], na=False)] = social_media[i] social_media_df.loc[:, &#39;product&#39;][social_media_df[&#39;item&#39;] .str.contains(products_regex[i], na=False)] = products[i] social_media_df = social_media_df[social_media_df[&#39;product&#39;] != &#39;product&#39;] .reset_index(drop=True) quantity = social_media_df[&#39;item&#39;] .str.extract(&#39;( d[ s| d]? d? d? s? d? d? d? s? d? d? d?)&#39;, expand=False).str.replace(&#39; s&#39;, &quot;&quot;) social_media_df[&#39;quantity&#39;] = pd.to_numeric(quantity) social_media_df.loc[64, &#39;quantity&#39;] = 5000 social_media_df[&#39;unit_price&#39;] = social_media_df[&#39;price&#39;] / social_media_df[&#39;quantity&#39;] social_media_df[&#39;unit_usd&#39;] = social_media_df[&#39;usd&#39;] / social_media_df[&#39;quantity&#39;] del [social_media_regex, social_media, products_regex, products, subset, i, quantity] print(social_media_df.shape) social_media_df.head() . (74, 8) . item price usd company product quantity unit_price unit_usd . 0 100 Youtube likes just 8 USD! | 0.032760 | 19.29 | YouTube | likes | 100 | 0.000328 | 0.192900 | . 1 100 Youtube subscriber just 10 USD! | 0.040950 | 24.11 | YouTube | subscribers | 100 | 0.000409 | 0.241100 | . 2 100 Youtube unlike just 10 USD! | 0.040929 | 24.10 | YouTube | likes | 100 | 0.000409 | 0.241000 | . 3 1000 Youtube views just 10 USD | 0.040960 | 24.12 | YouTube | views | 1000 | 0.000041 | 0.024120 | . 4 500 000 Real High Retention Youtube views | 2.747742 | 1617.76 | YouTube | views | 500000 | 0.000005 | 0.003236 | . Gathering social media content into a coherent data frame was a little more work. The code above extracts the per unit cost in purchasing an additional like, subscriber, view or comment for a given social media account. Most listings are regarding Facebook and Youtube. The code above uses the item descriptions to extract the number and type of unit being sold, and creates several new columns that reflect this while facilitating further analysis. . youtube = social_media_df[social_media_df[&#39;company&#39;]==&#39;YouTube&#39;] .groupby(&#39;product&#39;)[&#39;unit_usd&#39;].median().reset_index() .sort_values(&#39;unit_usd&#39;, ascending=False).set_index(&#39;product&#39;) plt.style.use(&quot;seaborn-whitegrid&quot;) fig, ax = plt.subplots(figsize=(15,10)) ax.bar(youtube.index, youtube[&#39;unit_usd&#39;], color = &#39;#228833&#39;) ax.set_xticklabels(youtube.index, size = 20) ax.tick_params(axis=&#39;y&#39;, labelsize= 15) ax.set_ylabel(&quot;Median Cost per Unit (USD)&quot;, size = 20) plt.show() . Pictured above, is the data for YouTube. According to all the postings, each additional comment was worth around 60 cents of a 2021 USD, putting it higher than subscribers, likes or views. Vast majority of these listings indicate that each product is of &#39;high quality&#39; meaning they are such that bot detecting software would not cleanse them. This usually indicates click farms (mostly from third world countries in which people are paid to constantly create new accounts and provide social media engagement) but such a claim cannot be ascertained from given data alone. . Below, I quickly calculate the expected per-unit-cost of a Facebook like, which seems to be a somewhat lower value than YouTube likes. . fb_like = social_media_df[(social_media_df[&#39;company&#39;]==&#39;Facebook&#39;) &amp; (social_media_df[&#39;product&#39;]==&#39;likes&#39;)] .loc[:, &#39;unit_usd&#39;].median() print(&quot;The expected per-unit cost of a Facebook like is&quot;, round(fb_like*100, 2), &quot;cents (2021 $USD).&quot;) . The expected per-unit cost of a Facebook like is 12.48 cents (2021 $USD). . Documents . doc_regex = [&#39;[P|p]assport&#39;, &#39;[D|d]river[ &#39;]?s[ s]?&#39;] doc = [&quot;Passport&quot;, &quot;Driver&#39;s License&quot;] docs_df = pd.DataFrame(columns=[&#39;item&#39;, &#39;price&#39;, &#39;usd&#39;]) for i in range(2): subset = dw_data[dw_data[&#39;category1&#39;] == &#39;Physical documents&#39;] subset = subset[subset[&#39;item&#39;].str.contains(doc_regex[i], na=False)] docs_df = docs_df.append(subset[docs_df.columns], ignore_index=True) docs_df[&#39;document&#39;] = &#39;document&#39; for i in range(2): docs_df.loc[:, &#39;document&#39;][docs_df[&#39;item&#39;] .str.contains(doc_regex[i], na=False)] = doc[i] docs_df.loc[:, &#39;document&#39;][docs_df[&#39;item&#39;] .str.contains(&#39;Passport[ s]?[+]&#39;)] = &quot;Passport+ID+Driver&#39;s License&quot; docs_df = docs_df[~docs_df[&#39;item&#39;].str.contains(&#39;emplate&#39;)].reset_index(drop=True) del [doc, doc_regex, i, subset] print(docs_df.shape) docs_df.head() . (114, 4) . item price usd document . 0 Fake Danish Passport | 2.808987 | 1653.82 | Passport | . 1 Fake Lithuanian Passport (old version) | 3.803150 | 2239.14 | Passport | . 2 Fake Lithuanian Passport | 2.475635 | 1457.55 | Passport | . 3 Netherlands Physical Passport + DL + ID CARD | 7.761003 | 4569.36 | Passport+ID+Driver&#39;s License | . 4 Pysical Fake Passports and IDs | 0.015551 | 9.16 | Passport | . This data frame was created in a way similar to the social media one. Item descriptions were used to separate out the type of &#39;product&#39; being sold. Three specific groups were identified: Passports, Driver&#39;s Licenses and a combination product of Passport, ID and Driver&#39;s License. These are worldwide so documents belong to numerous countries and/or states. For the sake of simplicity, the median cost is calculated on a worldwide basis. Counterfeit document listing also include a lot of templates being sold, which were filtered out, given that their values were significantly lower. . documents = docs_df.groupby(&#39;document&#39;)[&#39;usd&#39;].median().reset_index() .sort_values(&#39;usd&#39;, ascending=False).set_index(&#39;document&#39;) plt.style.use(&quot;seaborn-whitegrid&quot;) fig, ax = plt.subplots(figsize=(15,10)) ax.bar(documents.index, documents[&#39;usd&#39;], color = &#39;#AA3377&#39;) ax.set_xticklabels(documents.index, size = 15) ax.set_ylabel(&quot;Median Cost (USD)&quot;, size = 20) ax.tick_params(axis=&#39;y&#39;, labelsize= 15) plt.show() . Median costs were calcualted given that there are numerous countries listed, with varying degrees of value associated with their documentation, as well as several prominent outliers. While this category provides listings for real documents, that is, documents that are actually harder to detect as illegaly obtained and that exist in some database, there are many from the Fake category that slip into this one. They usually cost much less but the wording in the item description is difficult to use in filtering them out. Hopefully, the median expectation protects against these outlier effects. . Cigarettes . cigs_regex = [&#39;[D|d][U|u][N|n][H|h][I|i][L|l][L|l]&#39;, &#39;[B|b][O|o][N|n][D|d]&#39;, &#39;[V|v][O|o][G|g][U|u][E|e]&#39;, &#39;[W|w][I|i][N|n][S|s][T|t][O|o][N|n]&#39;, &#39;[M|m][A|a][R|r][L|l][B|b][O|o][R|r][O|o]&#39;, &#39;[P|p][A|a][L|l][L|l][ s]?[M|m][A|a][L|l][L|l]&#39;, &#39;[L|l][ s]?[&amp;][ s]?[M|m]&#39;, &#39;[L|l][U|u][C|c][K|k][Y|y]&#39;, &#39;[C|c][A|a][M|m][E|e][L|l]&#39;, &#39;[C|c][H|h][E|e][S|s][T|t][E|e][R|r]&#39;, &#39;[D|d][A|a][V|v][I|i][D|d][O|o]&#39;, &#39;[P|p][A|a][R|r][L|l][I|i][A|a][M|m]&#39;, &#39;[V|v][I|i][R|r][G|g][I|i][N|n][I|i][A|a]&#39;, &#39;[R|r][E|e][D|d][ s]?[&amp;][ s]?[W|w][H|h][I|i][T|t][E|e]&#39;] cigs = [&#39;Dunhill&#39;, &#39;Bond&#39;, &#39;Vogue&#39;, &#39;Winston&#39;, &#39;Marlboro&#39;, &#39;Pall Mall&#39;, &#39;L&amp;M&#39;, &#39;Lucky Strike&#39;, &#39;Camel&#39;, &#39;Chesterfield&#39;, &#39;Davidoff&#39;, &#39;Parliament&#39;, &#39;Virginia&#39;, &#39;Red&amp;White&#39;] cigs_df = pd.DataFrame(columns=[&#39;item&#39;, &#39;price&#39;, &#39;usd&#39;]) for i in range(10): subset = dw_data[dw_data[&#39;category1&#39;] == &#39;Smoked&#39;] subset = subset[subset[&#39;item&#39;].str.contains(cigs_regex[i], na=False)] cigs_df = cigs_df.append(subset[cigs_df.columns], ignore_index=True) cigs_df[&#39;brand&#39;] = &#39;brand&#39; for i in range(14): cigs_df.loc[:, &#39;brand&#39;][cigs_df[&#39;item&#39;] .str.contains(cigs_regex[i], na=False)] = cigs[i] # almost all original prices are listed for 10 packs, so I divide by 10 to get pack price # but sometimes it&#39;s a single pack listed and that&#39;s why I did this division only when # the total price listed was above 10USD cigs_df[&#39;unit_cost&#39;] = cigs_df[&#39;usd&#39;] cigs_df.loc[:, &#39;unit_cost&#39;][cigs_df[&#39;unit_cost&#39;] &gt; 10] = cigs_df[&#39;unit_cost&#39;] / 10 cigs_df = cigs_df.reset_index(drop=True) del [cigs_regex, cigs, subset, i] print(cigs_df.shape) cigs_df.head() . (101, 5) . item price usd brand unit_cost . 0 Dunhill Fine Cut Dark Blue (10 packs x 20 ciga... | 0.160849 | 94.70 | Dunhill | 9.470 | . 1 DUNHILL Cheap Cigarettes to USA and EU | 0.156015 | 91.86 | Dunhill | 9.186 | . 2 Dunhill Fine Cut Black (10 packs x 20 cigarettes) | 0.160806 | 94.68 | Dunhill | 9.468 | . 3 Copy of Dunhill Fine Cut Black (10 packs x 20 ... | 0.091288 | 53.75 | Dunhill | 5.375 | . 4 Bond Cheap Cigarettes to USA and EU | 0.088071 | 51.85 | Bond | 5.185 | . Again, repeating the procedure used for the social media and documentation data frames, once again I go through the item descriptions and extract all the relevant cigarette brands to group by later. Furthermore, it is clear from the description that almost every single listed price is for a product consisting of 10 packs with 20 cigarettes each. Therefore, the Bitcoin price was converted to US Dollar values, and divided by 10, to get the cost of a single pack for each brand. . cigarettes = cigs_df.groupby(&#39;brand&#39;)[&#39;unit_cost&#39;].median().reset_index() .sort_values(&#39;unit_cost&#39;, ascending=False).set_index(&#39;brand&#39;) plt.style.use(&quot;seaborn-whitegrid&quot;) fig, ax = plt.subplots(figsize=(15,10)) ax.bar(cigarettes.index, cigarettes[&#39;unit_cost&#39;], color = &#39;#CC3311&#39;) ax.set_xticklabels(cigarettes.index, rotation=80, size = 20) ax.set_ylabel(&quot;Median Cost per Pack (USD)&quot;, size = 20) ax.tick_params(axis=&#39;y&#39;, labelsize= 15) plt.show() . As can be seen in the plot above, the brands are sorted by cost. The prices are median costs, per pack, in 2021 $USD. Surprisingly, they don&#39;t differ significantly from prices in states with low to moderate taxes. However, they are much smaller than those in states like New York, which have costs of around $15 per pack, easily. . Conclusion . As an initial look into the illegal dealings on the Dark Web, this project is appropriate. It allows for a preliminary sense of how products are listed, what the scope of the markets is, how data is organized and what possible insights can be gleaned from it. Furthermore, it illuminates all the issues present in trying to make sense of it all. The prices are listed in Bitcoin and held online for unknown periods of time, even as Bitcoin fluctuates. Knowing the possible range for a year helps in narrowing down the expected cost values. However, error bars need to be created to show the amount of uncertainty in this approach. . With more computing power and detailed string parsing scripts, I would be willing to take a crack at the 1.6TB data set. Price differences between legal and illegal products can illuminate countless premiums customers are willing to pay on various products, which is a worthwhile endeavor for any economist to pursue. . For the data and other notebooks, see github.com/antoniojurlina/learning_python. .",
            "url": "https://antoniojurlina.github.io/portfolio/2021/05/07/Dark_Web.html",
            "relUrl": "/2021/05/07/Dark_Web.html",
            "date": " • May 7, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Economic Freedom And Growth",
            "content": "University of Maine – School of Economics . Economic Freedom and Growth | . ECO 530: ECONOMETRICS | . Antonio Jurlina . 12-3-2018 . | . . Contents: . Topic and Motivation——————————————————— 2 . | Literature Review————————————————————- 3 . | Econometric Model———————————————————– 4 . | Preliminary Estimates——————————————————– 7 . | Testing————————————————————————– 8 . | Revised Estimates————————————————————- 13 . | Conclusion——————————————————————— 16 . | Bibliography——————————————————————- 18 . | Appendices: . | Index Area Components——————————————– 20 . | Summary Statistics————————————————– 21 . | Summary Graphs—————————————————- 25 . | Residuals Plots (before)——————————————— 29 . | Residuals Plots (after)———————————————– 30 . | EViews Code——————————————————— 31 . | Economic Freedom and Growth . Topic and Motivation | Going through an undergraduate career in economics, one starts off by learning the classical assumptions governing the thinking process. They should sound familiar to most – people face tradeoffs, respond to incentives and think at the margin, societies face a tradeoff between inflation and unemployment in the short run and trade can make everyone better off, among others. These assumptions get challenged along the way, thereby structuring a solid reasoning foundation. The most useful way to challenge them has been observing the real world and finding the fault in the simplicity of the assumptions. . Observing real world data, it soon becomes obvious that individuals are not always rational thinkers operating at the margin (Kahneman &amp; Tversky, 1979) and that markets might not always be the best way to organize economic activity. Having an education with an emphasis on micro processes, macroeconomics sometimes takes a back seat and the ability to study real world interactions gives place to perusing (neo)classical theory. This leaves students with having to just accept at face value all about comparative advantage (Ricardo, 1817), the ability of markets to allocate resources and foster growth (Smith, 1776) and much more. . Without any individual econometric experience in dealing with country level data (prior to this semester) it seemed that pushing against the knowledge ceiling in this particular direction, would be an interesting project. I had decided to pursue this, hoping I could cross the adaptive valley along the way. Therefore, this research paper is going to examine if economic freedom is conducive to growth. Specifically, it will attempt to do so by deconstructing an index of economic freedom and testing the effect of all its elements on growth. This should provide an insight into macroeconomic econometrics dealing with panel data, all the parameter identification issues that usually come along with it and possibly prove (or disprove) some theoretical assumptions. The goal is to increase my econometric toolkit, with all the results that come from it as an added knowledge bonus. . Literature Review | Adam Smith (1776), with the publication of the Wealth of the Nations, instigated a debate around the causes of economic growth. Although mercantilism had dominated the period of late Renaissance in Europe and powerful merchants had built routes based on the belief that trade would benefit them greatly (McCusker &amp; Morgan, 2001), it wasn’t until Smith’s work had been published that attention turned towards free trade, production advantage, economies of scale and institutions (or lack thereof) intended to orchestrate this in unison. This work was further expanded by Ricardo (1817), who ushered the realization that benefits can be acquired even by those countries that are not the most efficient suppliers around. Eventually, economic growth was taken up by the likes of Solow (1956), who had expanded the Harrod-Domar model (Domar, 1946; Harrod, 1939) so that growth is represented as function of capital, labor and technology (with more optimistic limitations). . Following Solow’s work, Kuznets (1973) argued that, while necessary, technology itself wouldn’t suffice in producing measurable growth. He claimed that growth would induce change along the way (something along the lines of Schumpeter, 1942), and all the conflict would have to be resolved cost-effectively through institutions designed to do so. Only then, with conflict resolution costs smaller than benefits of growth, would long-term economic progress occur. Finally, there is Milton Friedman (1962), crafting institutional approach along more libertarian lines, arguing for a government that is there to promote safety, monopolize violence and influence the economy through the money supply. He also argued for the removal of major trade barriers as the only way to introduce stable equilibria. . More recent work had found that property rights, monetary stability, and freedom to trade internationally all have visible impact on growth (Ayal &amp; Karras, 1998; Barro, 1991; Easterly, 1992; Knack &amp; Keefer, 1995; Torstensson, 1994). Additionally, previously underdeveloped, closed-off, and/or countries with centralized economies had all undergone drastic economic changes (in the positive direction) upon loosening institutional grips, opening towards the world and openly stifling hierarchical corruption. This can be observed in the economies of Taiwan, Singapore and Hong Kong, with China following closely upon realizing its neighbors had adopted a slightly more laissez-faire approach and experienced significant growth (Naughton, 2007). . Market equilibria inside closed economies adjust themselves according to supply and demand interactions and institutional involvement. With constraints effectively placed to incorporate the costs of most inefficiencies, effective resource allocation is determined on aggregate, through interactions of all the individual participants. With current levels of globalization and economic interconnectedness, eliminating quotas and barriers results in a world-wide market place with freer price points. This, much like on a single-country level, is an amalgamation of countless interactions producing an inherent equilibrium. Depending on the institutional restrictions imposed by all the individual players (and their size), this equilibrium will inch towards comparative efficiency, fostering more growth. With the readjustment of the production possibility frontiers to accommodate the new demand and supply pressures, Mundell and Fleming (Mundell, 1963; Fleming, 1962) identify certain factors affecting GDP levels of open-economies: fiscal policy, monetary policy, and foreign trade shifts. Even if Leonteif’s (1953) observations (the failure of H-O theorem) hold across countries, there is still an adjustment shift according to the world market. . Finally, (Gwartney, Lawson, &amp; Block, 1996), have created an index consisting of all these factors influencing growth. The index rates the economic freedom of countries on a scale of 1 to 10, with 10 indicating a country that is completely free economically. The Economic Freedom Index (from here on referred to as EFI), is comprised of separate indices for the size of the government, legal system and property rights, freedom to trade internationally, stability of the monetary policy, and the number of regulatory obstacles. This index, and similar ones (such as the one produced by the Heritage Foundation) have been used in several ways in order to determine a possible causal link between economic freedom and economic growth (Berggren, 2003; Carlsson &amp; Lundström, 2002; de Haan &amp; Sturm, 2000; Gwartney, Lawson, &amp; Holcombe, 1999; Nelson &amp; Singh, 1998). . Econometric Model | The EFI is published yearly by the Fraser Institute. Latest edition (Gwartney et al., 2015) is comprised of five areas used to construct a scale of economic freedom, with each area rated on a scale of 1 to 10. Size of Government focuses on individual choice-making through market interactions, as opposed to relying on policy making. Countries with low levels of government spending, a smaller government enterprise sector, and lower tax rates earn the highest ratings in this area. Legal System and Property Rights focuses on unbiased judiciary systems, effective protection of private property and impartial enforcement of the law. Countries that satisfy these categories the best, score the highest in this area. Sound Money refers to money with a stable purchasing power over time. Countries that score high in this area, must follow policies and adopt institutions that lead to low rates of inflation and avoid regulations that limit the ability to use alternative currencies. Freedom to Trade Internationally focuses on the level and ease of interactions across the borders. To score high in this area, a country must have “low tariffs, easy clearance and efficient administration of customs, a freely convertible currency, and few controls on the movement of physical and human capital” (Gwartney, Lawson, &amp; Block, 2015). Regulation measures the access into markets and restrictions around economic interactions. To score high in this area, countries need to relax regulatory constraints around labor, product and credit markets. For more detail on the construction of each of these areas, see Appendix 1. . The model under consideration uses these areas as explanatory variables. This should help in determining the causal link, or at least, the sign of the relationship, between economic growth and factors determining classical assumptions around economic freedom. The model is as follows( text{ }) . [ text{GROWT}H_{i, left( t - 5 to t right)} = beta_{0} + beta_{1} text{GO}V_{i,t - 5} + beta_{2} text{LEGA}L_{i,t - 5} + beta_{3} text{MONE}Y_{i,t - 5} + beta_{4} text{TRAD}E_{i,t - 5} + beta_{5} text{REGULATIO}N_{i,t - 5} + beta_{6} text{ log} left( text{GDP} right){i,t - 5} + varepsilon{i,t} text{ } left( Equation 1 right)] . where the dependent variable represents growth of log GDP per capita over a 5-year period, ( beta_{1}) through ( beta_{5}) represent the five areas of EFI at the beginning of each 5-year period, ( beta_{6}) represents the log of GDP per capita at the beginning of each 5-year period and ( varepsilon) represents the error term. Each of these variables is defined across countries (i) and time (t, t-5), making this a fixed effects model. Country-level heterogeneity carries a lot of unobservable variables, so with fixed effects, the remaining variation can be used to causally identify the relationships of interest. The null hypotheses are that there is no significant effect between the five areas of EFI and growth of GDP per capita. The alternative hypotheses are that the higher a country scores in all five areas of EFI, the higher the log growth of GDP per capita, in accordance with classical assumptions. . Data . The data set used for this project was created using three different sources. The EFI was obtained from the Fraser Institute (“Economic Freedom of the World,” 2016), data on GDP per capita was obtained from the World Bank Group (“GDP per capita (current US$) | Data,” 2018), recorded in 2018 US dollars. GDP was chosen to be per capita specifically to avoid any issues with population size differences among countries. Finally, a dummy variable on whether nations are members of the OECD was created using the list of member nations from the OECD website (“OECD - Members and partners,” 2018). These variables are organized as panel data with 52 countries, ranging from 1970 to 2015. Countries were selected based on data availability, to avoid missing values that would result in omitted observations during estimation. Summary statistics (minimum, maximum, mean, and standard deviation) for all variables can be seen in Appendix 2 and graphs representing these variables, faceted by country, can be seen in Appendix 3. | . In the 2015 EFI, Hong Kong and Singapore were the top two countries, United States was 16th, Japan (26th), Germany (29th), South Korea (39th), Italy (68th), France (70th), Mexico (93rd), Russia (99th), China (111th), India (114th), and Brazil (118th). The 10 lowest-rated countries were Angola, Central African Republic, Zimbabwe, Algeria, Argentina, Syria, Chad, Libya, the Republic of Congo, and, in last place, Venezuela. . Figure 1. Economic Freedom of the World 2015 Report (The Fraser Institute) (Gwartney, Lawson, &amp; Block, 2015). . Preliminary Estimates | The first step of the analysis revolved around estimating an OLS version of the model in Equation 1. Results were estimated in three different ways – by grouping all countries together, by using only OECD member countries and by using only non-member countries. This dummy variable was introduced due to the special economic relationships fostered by OECD member nations, to stabilize unobservable heterogeneity between members and non-members. The use of the dummy variable was also inspired by previous research, especially that of Mankiw, Romer and Weil (1992). Detailed results are presented in Figure 2. . Figure 2. Panel Least Squares Regressions . Si . As Figure 2 shows, Freedom to Trade Internationally and Regulation have a significant effect across three model runs, and Sound Money has a significant effect for non-OECD countries only. Any one-point increase in the Freedom to Trade Internationally index is correlated with a 1.3 % (pooled), 1.7 % (non-OECD) and 0.8% (OECD) increase in the growth rate of GDP per capita, on average. Any one-point increase in the Regulation index is correlated with a 2.4 % (pooled), 2.4 % (non-OECD) and 2.5% (OECD) increase in the growth rate of GDP per capita, on average. Finally, any one-point increase in the Sound Money index for non-OECD countries is correlated with a 0.6 % decrease in the growth rate of GDP per capita, on average. To reiterate, an increase in index score across all three of the variables mentioned indicates an increase in economic freedom, as per EFI design. . Testing | Although the results seem significant at first glance, there are many causes for concern regarding the validity of parameter identification in a simple OLS approach to this data set. This section is dedicated to discovering possible violations of Gauss-Markovian assumptions and checking the validity of model design. . Multicollinearity . One of the primary issues with deconstructing an index is the causal relationships between some of the subcomponents. It seems reasonable to assume that size of the government, amount of regulation and property rights are correlated with one another. This can result in multicollinearity among explanatory variables, affecting the robustness of the estimates. The correlation matrix in Figure 3 indicates strong correlation (over 0.5) between the five areas of the EFI. This serves as a rough estimate of multicollinearity present in the model, indicating that estimates need to be interpreted conservatively. For future reference, multicollinearity should be further confirmed by estimating the model and changing the data slightly, many times over, seeing how the estimates react. Also, dependent variables should be dropped, and model estimated without some, to see the effect on estimates. Significant estimate changes in both these approaches would indicate a presence of multicollinearity. Finally, a variance inflation factor should be calculated, as it gives an exact numeric value for evaluation. Since multicollinearity doesn’t change the BLUE properties of the model, and due to time limitations, the model will be left as is. . Figure 3. Correlation Matrix . . Autocorrelation . Since the primary statistical software used in estimation doesn’t allow for direct autocorrelation testing, several indirect ways shall be explored, to detect any potential autocorrelation. First, simply observing graphs of residuals from the three OLS approaches, can be very indicative of any potential autocorrelation. Indeed, by looking at the attached graphs (see Appendix 4), it seems highly possible that autocorrelation is present. The order is harder to discern. Furthermore, Durbin-Watson statistic can be used for identification of first-order autocorrelation. The autocorrelation coefficient, ( rho), (with stable errors) is located on the interval (- 1 &lt; rho &lt; 1), and the Durbin-Watson test statistic is approximately equal to 4, 2 and 0, for the ( rho) values of -1, 0, and 1, respectively. Therefore, the d-statistic serves as a rough guide of first order autocorrelation. In the first (pooled) OLS estimate, d is 2.7. Being further from 2 (in the positive direction), indicates that autocorrelation is more likely. The same can be said for the d values of the second (non-OECD) and third (OECD) OLS estimates, for which d values are 2.4 and 2.9, respectively (see Figure 2). Finally, a feasible GLS model is estimated, with the addition of autocorrelation parameters. These are added individually, starting with a parameter for first order autocorrelation, up to the point where their p-values start to become insignificant at conventional confidence levels (see Figure 4). The results indicate a presence of first and second order autocorrelation, with any subsequent level added failing to pass as significant or reducing the number of observations past the optimal point. . Figure 4. FGLS Regression - Sensitivity Testing for Autocorrelation . Note: This approach assumes there might be first, second and fifth order autocorrelation. The fifth order autocorrelation is assumed because growth is studied through 5-year periods. Sensitivity analysis is looking for AR terms that are significant at standard confidence levels and that produce d-statistics closest to 2. Significance levels are as follows: * - 90 % significance / ** - 95 % significance / *** - 99 % significance. . Heteroskedasticity . After scouring EViews help pages and related forums and blogposts, I have concluded that the current version of the statistical software just doesn’t provide support when it comes to testing for heteroskedasticity in panel data through direct tests. With that in mind, there were two options left for attempting to detect possible heteroskedasticity in the data. First approach is a common-sense (backed by econometrics textbooks - Guajarati, 1987; Wooldridge, 2016) approach, that assumes there is high probability of heteroskedastic errors occurring in cross-sectional data. This seems intuitively reasonable as well – countries vary greatly in GDP per capita and economic freedom measures, indicating a strong possibility of errors having varying degrees of statistical dispersion. Furthermore, Figure 5 plots residuals against fitted values, for the three OLS estimates (pooled, non-OECD, and OECD). These graphs indicate that errors are indeed not uniformly dispersed and that heteroskedasticity is likely present between cross-sections (i.e. countries). Finally, plots showing within-country fitted values and residuals aren’t feasible since there are only 10 periods under consideration meaning that there aren’t enough points to visually estimate the shape of error dispersion. . Figure 5. Residuals versus Fitted Values plots . . Redundant Fixed Effects . Figure 6 shows the results of redundant fixed effects tests, performed on the three OLS models. With future revised estimation in mind, the tests were completed for fixed cross-sectional effects, fixed period effects, and both. In each case, across all the model version, tests confirm that all model specifications are supported, with significant p-values across multiple tests. . Figure 6. Redundant Fixed Effects Test . . Hausman Test . Hausman Test null hypothesis states that there is no correlation between unique errors and regressors (meaning that the random effects model is preferred) against an alternative that there is correlation between unique errors and regressors (meaning that the fixed effects model is preferred). This test could only be performed on cross-sectional fixed effects and not two-way fixed effects since EViews doesn’t estimate two-way random effects tests on unbalanced data for the purposes of further testing. Hausman test results (see Figure 7) reject the null hypothesis and the alternative is accepted – fixed effects model is appropriate. . Figure 7. Random versus Fixed Effects Test . Note: * - 90 % significance / ** - 95 % significance / *** - 99 % significance. . Revised Estimates | Following all the tests performed, I have decided to reformulate the previous cross-section fixed effects OLS model. For more precise parameter identification and robust standard errors, cross-sectional heteroskedasticity and first (and possibly second) order autocorrelation need to be addressed. Therefore, the revised model is structured as a cross-section fixed effects GLS model, with two terms for autocorrelation and cross-section weights which assume the presence of heteroskedasticity in the relevant dimension. Estimates for this model are presented in Figure 8, split up between estimates for all countries, only non-OECD countries, and only OECD countries. . As Figure 8 shows, Freedom to Trade Internationally and Sound Money have a significant effect across three model runs, and Regulation has a significant effect for non-OECD countries only. Any one-point increase in the Freedom to Trade Internationally index is correlated with a 1.3 % (pooled), 1.7 % (non-OECD) and 1% (OECD) increase in the growth rate of GDP per capita, on average. Any one-point increase in the Sound Money index is correlated with a 0.7 % (pooled), 0.9 % (non-OECD) and 0.6% (OECD) increase in the growth rate of GDP per capita, on average. Any one-point increase in the Regulation index for non-OECD countries is correlated with a 1.3 % increase in the growth rate of GDP per capita, on average. Finally, any one-point increase in the Size of Government index for pooled countries is correlated with a 0.5 % increase in the growth rate of GDP per capita, on average. To reiterate, an increase in index scores across all three of the variables mentioned indicates an increase in economic freedom, as per EFI design. . Figure 8. Panel EGLS Regression (Cross-Section Weights) . Note: * - 90 % significance / ** - 95 % significance / *** - 99 % significance. . Moreover, to confirm that the revised model significantly diminishes heteroskedasticity and autocorrelation detected previously, Figure 8 reports the Durbin-Watson statistic and Figure 9 shows the residual plots. The Durbin-Watson (d) statistic went from 2.7 to 1.8 (pooled), 2.4 to 2.1 (non-OECD), and 2.9 to 1.7 (OECD). Since a d value of 2 indicates that ( rho) is 0, this indicates a reduction in residual trend correlation. Additionally, Appendix 5 reports the trend of residuals across periods (compared with the OLS estimated ones), indicating a smoothening. Finally, Figure 9 reports the error dispersion (compared with the OLS estimated ones), indicating more uniform dispersion (homoskedasticity). . Figure 9. Residuals versus Fitted Values plots . . Conclusion | This paper finds a significant relationship between freedom to trade internationally and economic growth. This freedom is reflected in lower tariffs, few regulations on movement of human and physical capital, easily convertible currency and simple customs clearance operations. This finding mirrors that of Gwartney and Torstensson (1999; 1994), and contradicts the findings of Ayal and Karras (1998), who find a negative relationship between freedom to trade and economic growth. This finding holds for all countries pooled together, only non-OECD countries, as well as OECD member nations. Furthermore, this research finds that pursuing low inflation and allowing free access to alternative currency use has a small negative impact on economic growth (between 0.6% and 0.9% for each EFI area unit increase). This result directly contradicts that of Ayal and Karras (1998) and Barro (1996). There is also significant evidence that less stringent regulation positively affects economic growth for non-OECD countries only. This reflects the findings of Barro, Torstensson and Knack &amp; Keefer (Barro, 1996; Knack &amp; Keefer, 1995; Torstensson, 1994). Finally, there is significant evidence that smaller governments, that intervene economically less often, are positively correlated with economic growth. This has only been observed for the pooled data set and the effect was only 0.05%. This finding is mirrored in a more robust way in other research (Barro, 1991; Gwartney et al., 1999; Knack &amp; Keefer, 1995). . Across all model formulations, freedom to trade internationally remained very robust. These results support classical economic theory (Ricardo, 1817; Smith, 1776), as well as more modern assumptions (Friedman, 1962). Monetary stability through low inflation and the freedom to use alternate currencies seemed likely to be correlated with economic growth. However, research did not support this hypothesis. There are a few reasons that might explain this finding. Subcomponents of this area of the index might be constructed out of elements with opposite effects. Also, most countries in the data set do not wield the economic power of the United States and are economically tied to the fluctuations of more influential currencies. Therefore, they are unable to produce sound monetary policy and often attempt to restrict the power of foreign currencies in the domestic marketplace. If these countries experience increased growth rates, this area of the index does not predict development as assumed. Free movement into markets, as pictured through the regulation variable, is only significant for non-OECD countries, most of which are underdeveloped. This could indicate that lax regulation fosters growth on the way to the status of a first-world country. However, countries that had already reached these levels of development are not experiencing such growth rates and often begin introducing new regulation when they become appropriately placed on the Kuznets curve to do so. This is often regulation that deals with various market inefficiencies (externalities, informational asymmetry, etc.). . Limitations and future research . This data set was somewhat unbalanced (missing periods for a few cross-sections), resulting in the omission of those observations. Along with balanced panel data, the set needs to extend over a longer time frame, given that in the process of correcting for autocorrelation, the number of observations got further reduced. It would also be useful to detect breakpoints in the time series, centered around significant economic events (like the Great Recession), and perform the estimation around them. Much like a longer time frame, more countries included in the set would be useful. The issue lies in procuring the necessary data, especially further into the past, given that some countries do not provide any data or provide data that is highly questionable. . Bibliography | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | Ayal, E. B., &amp; Karras, G. (1998). Components of Economic Freedom and Growth: An Empirical Study. The Journal of Developing Areas, 32(3), 327–338.Barro, R. J. (1991). Economic Growth in a Cross Section of Countries. The Quarterly Journal of Economics, 106(2), 407–443. https://doi.org/10.2307/2937943Barro, R. J. (1996). Democracy and Growth. Journal of Economic Growth, 1(1), 1–27.Berggren, N. (2003). The Benefits of Economic Freedom: A Survey. The Independent Review, 8(2), 193–211.Carlsson, F., &amp; Lundström, S. (2002). Economic freedom and growth: Decomposing the effects. Public Choice, 112, 335–344. https://doi.org/10.1023/a:1019968525415de Haan, J., &amp; Sturm, J.-E. (2000). On the relationship between economic freedom and economic growth. European Journal of Political Economy, 16(2), 215–241. https://doi.org/10.1016/S0176-2680(99)00065-8Domar, E. D. (1946). Capital Expansion, Rate of Growth, and Employment. Econometrica, 14(2), 137–147. https://doi.org/10.2307/1905364Easterly, W. (1992). Marginal income tax rates and economic growth in developing countries (No. WPS1050) (p. 1). The World Bank. Retrieved from http://documents.worldbank.org/curated/en/432391468766196026/Marginal-income-tax-rates-and-economic-growth-in-developing-countriesEconomic Freedom of the World. (2016, December 22). Retrieved October 9, 2018, from http://bit.ly/2h5xBVIFriedman, M. (1962). Capitalism and Freedom (1st ed.). University of Chicago Press. Retrieved from https://www.goodreads.com/work/best_book/1534488-capitalism-and-freedomGDP per capita (current US$) | Data. (2018). Retrieved October 9, 2018, from https://data.worldbank.org/indicator/NY.GDP.PCAP.CDGuajarati, D. N. (1987). Basic Econometrics (4th ed.).Gwartney, J. D., Lawson, R. A., &amp; Block, W. (1996). Economic Freedom of the World: 1975-1995 (p. 342). The Fraser Institute. Retrieved from http://bit.ly/2jUkBGRGwartney, J. D., Lawson, R. A., &amp; Holcombe, R. G. (1999). Economic Freedom and the Environment for Economic Growth. Journal of Institutional and Theoretical Economics, 155(4), 643–663.Harrod, R. F. (1939). An Essay in Dynamic Theory. The Economic Journal, 49(193), 14–33. https://doi.org/10.2307/2225181J. M. Fleming, “Domestic Financial Policies under Fixed and Floating Exchange Rates,” IMF Staff Papers, Vol. 9, 1962, pp. 369-379. doi:10.2307/3866091Kahneman, D., &amp; Tversky, A. (1979). Prospect Theory: An Analysis of Decision under Risk. Econometrica, 47(2), 263–291. https://doi.org/10.2307/1914185Knack, S., &amp; Keefer, P. (1995). Institutions and Economic Performance: Cross-Country Tests Using Alternative Institutional Measures. Economics &amp; Politics, 7(3), 207–227. https://doi.org/10.1111/j.1468-0343.1995.tb00111.xKuznets, S. (1973). Modern Economic Growth: Findings and Reflections. The American Economic Review, 63(3), 247–258.Leontief, W. (1953). Domestic Production and Foreign Trade; The American Capital Position Re-Examined. Proceedings of the American Philosophical Society, 97(4), 332–349.Mankiw, N. G., Romer, D., &amp; Weil, D. N. (1992). A Contribution to the Empirics of Economic Growth. The Quarterly Journal of Economics, 407–437. https://doi.org/10.3386/w3541McCusker, J., &amp; Morgan, K. (Eds.). (2001). The Early Modern Atlantic Economy. Cambridge: Cambridge University Press. doi:10.1017/CBO9780511523878Mundell, R. A. (1963). Capital Mobility and Stabilization Policy under Fixed and Flexible Exchange Rates. The Canadian Journal of Economics and Political Science / Revue Canadienne d’Economique et de Science Politique, 29(4), 475–485. https://doi.org/10.2307/139336Naughton, B. (2007). The Chinese economy: transitions and growth. Cambridge, Mass: MIT Press.Nelson, M. A., &amp; Singh, R. D. (1998). Democracy, Economic Freedom, Fiscal Policy, and Growth in LDCs: A Fresh Look. Economic Development and Cultural Change, 46(4), 677–696. https://doi.org/10.1086/452369OECD - Members and partners. (2018, July). Retrieved December 12, 2018, from http://www.oecd.org/about/membersandpartners/Ricardo, D. (2004). On the Principles of Political Economy and Taxation. London: Dover Publications.Schumpeter, J. (1942). Capitalism, Socialism and Democracy (Vol. 1). Routledge. Retrieved from https://www.goodreads.com/work/best_book/129884-capitalism-socialism-and-democracySmith, A. (2003). An Inquiry into the Nature and Causes of the Wealth of Nations. Bantam Classics.Solow, R. M. (1956). A Contribution to the Theory of Economic Growth. The Quarterly Journal of Economics, 70(1), 65. https://doi.org/10.2307/1884513Torstensson, J. (1994). Property Rights and Economic Growth: An Empirical Study. Kyklos, 47(2), 231–247.Wooldridge, J. M. (2016). Introductory Econometrics: A Modern Approach (6th ed.). Thomson South-Western. | . | Appendix 1 – Index Area Components . 1. Size of Government . A. Government consumption . B. Transfers and subsidies . C. Government enterprises and investment . D. Top marginal tax rate . (i) Top marginal income tax rate . (ii) Top marginal income and payroll tax rate . 2. Legal System and Property Rights . A. Judicial independence . B. Impartial courts . C. Protection of property rights . D. Military interference in rule of law and politics . E. Integrity of the legal system . F. Legal enforcement of contracts . G. Regulatory costs of the sale of real property . H. Reliability of police . I. Business costs of crime . 3. Sound Money . A. Money growth . B. Standard deviation of inflation . C. Inflation: most recent year . D. Freedom to own foreign currency bank accounts . 4. Freedom to Trade Internationally . A. Tariffs . (i) Revenue from trade taxes (% of trade sector) . (ii) Mean tariff rate . (iii) Standard deviation of tariff rates . B. Regulatory trade barriers . (i) Non-tariff trade barriers . (ii) Compliance costs of importing and exporting . C. Black-market exchange rates . D. Controls of the movement of capital and people . (i) Foreign ownership/investment restrictions . (ii) Capital controls . (iii) Freedom of foreigners to visit . 5. Regulation . A. Credit market regulations . (i) Ownership of banks . (ii) Private sector credit . (iii) Interest rate controls/negative real interest rates . B. Labor market regulations . (i) Hiring regulations and minimum wage . (ii) Hiring and firing regulations . (iii) Centralized collective bargaining . (iv) Hours regulations . (v) Mandated cost of worker dismissal . (vi) Conscription . C. Business regulations . (i) Administrative requirements . (ii) Bureaucracy costs . (iii) Starting a business . (iv) Extra payments /bribes /favoritism . (v) Licensing restrictions . (vi) Cost of tax compliance . Appendix 2 – Summary Statistics . . . . . Appendix 3 – Summary Graphs . . . . . . . Appendix 4 – Residuals Plots (before) . . . . Appendix 5 – Residuals Plots (after) . . . . Appendix 6 – EViews Code . ‘Antonio Jurlina . ‘ECO 530 . ‘Final Project Program . ‘11/6/2018 . cd “E: UMaine Fall (2018) ECO 530 economicfreedom” . wfopen “gdp_data” . spool results . output(s) results . ‘creating variables necessary to introduce growth to the model . series pp = log(gdp) . series growth = (pp - pp(-1)) / 5 . ’’’’’’ Creating summary statistics, graphs and a covariance matrix’’’’’’’’’’’’’’’’’ . ’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’ . alpha country = countries . group dataset country year gdp gov growth*100 legal money oecd pp regulation trade . results.insert dataset . delete country . gdp.statby(max, min, nov, noa, p) countries . close gdp . graph ggdp.line(m, ab = histogram, panel = individual) gdp . ggdp.options connect . results.insert ggdp . growth.statby(max, min, nov, noa, p) countries . close growth . graph ggrowth.line(m, ab = histogram, panel = individual) growth . ggrowth.options connect . results.insert ggrowth . gov.statby(max, min, nov, noa, p) countries . close gov . graph ggov.line(m, ab = histogram, panel = individual) gov . ggov.options connect . results.insert ggov . legal.statby(max, min, nov, noa, p) countries . close legal . graph glegal.line(m, ab = histogram, panel = individual) legal . glegal.options connect . results.insert glegal . money.statby(max, min, nov, noa, p) countries . close money . graph gmoney.line(m, ab = histogram, panel = individual) money . gmoney.options connect . results.insert gmoney . trade.statby(max, min, nov, noa, p) countries . close trade . graph gtrade.line(m, ab = histogram, panel = individual) trade . gtrade.options connect . results.insert gtrade . regulation.statby(max, min, nov, noa, p) countries . close regulation . graph gregulation.line(m, ab = histogram, panel = individual) regulation . gregulation.options connect . results.insert gregulation . group variables growth gdp gov legal money regulation trade . matrix x = @cor(variables) . x.setcollabels growth gdp gov legal money regulation trade . x.setrowlabels growth gdp gov legal money regulation trade . x.displayname Correlation Matrix . x.label . results.insert x . delete ggdp ggov glegal gtrade gmoney gregulation ggrowth world_gdp usd . delete variables rank economic_freedom_summary_index x . results.displayname untitled01 “Data Set” . results.displayname untitled02 “GDP per capita” . results.displayname untitled03 “GDP per capita” . results.displayname untitled04 “Growth rate” . results.displayname untitled05 “Growth rate” . results.displayname untitled06 “Size of Government” . results.displayname untitled07 “Size of Government” . results.displayname untitled08 “Legal System &amp; Property Rights” . results.displayname untitled09 “Legal System &amp; Property Rights” . results.displayname untitled10 “Sound Money” . results.displayname untitled11 “Sound Money” . results.displayname untitled12 “Freedom to trade internationally” . results.displayname untitled13 “Freedom to trade internationally” . results.displayname untitled14 “Regulation” . results.displayname untitled15 “Regulation” . results.displayname untitled16 “Correlation Matrix” . ’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’ . ’’’’’’’ end of summary statistics ‘’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’ . ’’’’’’’ Fixed effects OLS models ‘’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’ . ’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’ . smpl @all . equation eq_a.ls(cx=f) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) . results.insert eq_a . results.displayname untitled17 “OLS (pooled)” . smpl if oecd = 0 . equation eq_b.ls(cx=f) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) . results.insert eq_b . results.displayname untitled18 “OLS (non-OECD)” . smpl if oecd = 1 . equation eq_c.ls(cx=f) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) . results.insert eq_c . results.displayname untitled19 “OLS (OECD)” . ’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’ . ’’’’’’’’’’ End of OLS estimation ‘’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’ . ’’’’’’ Tests ‘’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’ . ’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’ . smpl @all . equation eq_d.ls(cx=f, per=f) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) . eq_d.fixedtest(p) . results.displayname untitled20 “Redundancy Test a” . smpl if oecd = 0 . equation eq_e.ls(cx=f, per=f) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) . eq_e.fixedtest(p) . results.displayname untitled21 “Redundancy Test b” . smpl if oecd = 1 . equation eq_f.ls(cx=f, per=f) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) . eq_f.fixedtest(p) . results.displayname untitled22 “Redundancy Test c” . close eq_d . close eq_e . close eq_f . smpl @all . equation eq_d.ls(cx=r) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) . eq_d.ranhaus(p) . close eq_d . results.displayname untitled23 “RE vs FE Test a” . smpl if oecd = 0 . equation eq_e.ls(cx=r) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) . eq_e.ranhaus(p) . close eq_e . results.displayname untitled24 “RE vs FE Test b” . smpl if oecd = 1 . equation eq_f.ls(cx=r) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) . eq_f.ranhaus(p) . close eq_f . results.displayname untitled25 “RE vs FE Test c” . smpl @all . EQ_A.makeresids resid_a . graph res_a.spike(m, panel = combine) resid_a . res_a.options connect . results.insert res_a . results.displayname untitled26 “OLS (pooled) Residuals” . smpl if oecd = 0 . EQ_B.makeresids resid_b . graph res_b.spike(m, panel = combine) resid_b . res_b.options connect . results.insert res_b . results.displayname untitled27 “OLS (non-OECD) Residuals” . smpl if oecd = 1 . EQ_C.makeresids resid_c . graph res_c.spike(m, panel = combine) resid_c . res_c.options connect . results.insert res_c . results.displayname untitled28 “OLS (OECD) Residuals” . smpl @all . eq_a.forecast(e, g) growthf . graph hetero1.scat(panel = stack) growthf resid_a . hetero1.axis(b) angle(auto) . hetero1.legend position(LEFT) . hetero1.setelem(1) symbol(CIRCLE) linepattern(none) linecolor(@rgb(57,106,177)) . hetero1.setelem(1) legend(Fitted Values) . hetero1.setelem(2) legend(Residuals) . hetero1.setelem(1) axis(b) . results.insert hetero1 . results.displayname untitled29 “OLS (pooled) Residuals Plot” . smpl if oecd = 0 . eq_b.forecast(e, g) growthf . graph hetero2.scat(panel = stack) growthf resid_b . hetero2.axis(b) angle(auto) . hetero2.legend position(LEFT) . hetero2.setelem(1) symbol(CIRCLE) linepattern(none) linecolor(@rgb(57,106,177)) . hetero2.setelem(1) legend(Fitted Values) . hetero2.setelem(2) legend(Residuals) . hetero2.setelem(1) axis(b) . results.insert hetero2 . results.displayname untitled30 “OLS (non-OECD) Residuals Plot” . smpl if oecd = 1 . eq_c.forecast(e, g) growthf . graph hetero3.scat(panel = stack) growthf resid_c . hetero3.axis(b) angle(auto) . hetero3.legend position(LEFT) . hetero3.setelem(1) symbol(CIRCLE) linepattern(none) linecolor(@rgb(57,106,177)) . hetero3.setelem(1) legend(Fitted Values) . hetero3.setelem(2) legend(Residuals) . hetero3.setelem(1) axis(b) . results.insert hetero3 . results.displayname untitled31 “OLS (OECD) Residuals Plot” . delete res_a res_b res_c hetero1 hetero2 hetero3 resid_a resid_b resid_c growthf . smpl @all . equation eq_g.ls(cx=f) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) ar(1) ar(2) . results.insert eq_g . results.displayname untitled32 “OLS (pooled)” . smpl if oecd = 0 . equation eq_h.ls(cx=f) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) ar(1) ar(2) . results.insert eq_h . results.displayname untitled33 “OLS (non-OECD)” . smpl if oecd = 1 . equation eq_i.ls(cx=f) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) ar(1) ar(2) . results.insert eq_i . results.displayname untitled34 “OLS (OECD)” . ’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’ . ’’’’ end of tests ‘’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’’ . smpl @all . equation eq_j.ls(cx=f, wgt=cxdiag, deriv=aa) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) ar(1) ar(2) . results.insert eq_j . results.displayname untitled35 “OLS (pooled)” . smpl if oecd = 0 . equation eq_k.ls(cx=f, wgt=cxdiag, deriv=aa) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) ar(1) ar(2) . results.insert eq_k . results.displayname untitled36 “OLS (non-OECD)” . smpl if oecd = 1 . equation eq_l.ls(cx=f, wgt=cxdiag, deriv=aa) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) ar(1) ar(2) . results.insert eq_l . results.displayname untitled37 “OLS (OECD)” . smpl @all . equation eq_m.ls(cx=f, per=f) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) . results.insert eq_m . results.displayname untitled38 “OLS (pooled)” . smpl if oecd = 0 . equation eq_n.ls(cx=f, per=f) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) . results.insert eq_n . results.displayname untitled39 “OLS (non-OECD)” . smpl if oecd = 1 . equation eq_o.ls(cx=f, per=f) growth c gov(-1) legal(-1) money(-1) trade(-1) regulation(-1) pp(-1) . results.insert eq_o . results.displayname untitled40 “OLS (OECD)” . smpl @all . eq_j.makeresids resid_j . graph res_j.spike(m, panel = combine) resid_j . res_j.options connect . results.insert res_j . results.displayname untitled41 “OLS (pooled) Residuals” . smpl if oecd = 0 . eq_k.makeresids resid_k . graph res_k.spike(m, panel = combine) resid_k . res_k.options connect . results.insert res_k . results.displayname untitled42 “OLS (non-OECD) Residuals” . smpl if oecd = 1 . eq_l.makeresids resid_l . graph res_l.spike(m, panel = combine) resid_l . res_l.options connect . results.insert res_l . results.displayname untitled43 “OLS (OECD) Residuals” . smpl @all . eq_j.forecast(e, g) growthf . graph hetero1.scat(panel = stack) growthf resid_j . hetero1.axis(b) angle(auto) . hetero1.legend position(LEFT) . hetero1.setelem(1) symbol(CIRCLE) linepattern(none) linecolor(@rgb(57,106,177)) . hetero1.setelem(1) legend(Fitted Values) . hetero1.setelem(2) legend(Residuals) . hetero1.setelem(1) axis(b) . results.insert hetero1 . results.displayname untitled44 “OLS (pooled) Residuals Plot” . smpl if oecd = 0 . eq_k.forecast(e, g) growthf . graph hetero2.scat(panel = stack) growthf resid_k . hetero2.axis(b) angle(auto) . hetero2.legend position(LEFT) . hetero2.setelem(1) symbol(CIRCLE) linepattern(none) linecolor(@rgb(57,106,177)) . hetero2.setelem(1) legend(Fitted Values) . hetero2.setelem(2) legend(Residuals) . hetero2.setelem(1) axis(b) . results.insert hetero2 . results.displayname untitled45 “OLS (non-OECD) Residuals Plot” . smpl if oecd = 1 . eq_l.forecast(e, g) growthf . graph hetero3.scat(panel = stack) growthf resid_l . hetero3.axis(b) angle(auto) . hetero3.legend position(LEFT) . hetero3.setelem(1) symbol(CIRCLE) linepattern(none) linecolor(@rgb(57,106,177)) . hetero3.setelem(1) legend(Fitted Values) . hetero3.setelem(2) legend(Residuals) . hetero3.setelem(1) axis(b) . results.insert hetero3 . results.displayname untitled46 “OLS (OECD) Residuals Plot” . delete res_j res_k res_l hetero1 hetero2 hetero3 resid_j resid_k resid_l growthf . results.options displaynames .",
            "url": "https://antoniojurlina.github.io/portfolio/2019/03/07/Economic-Freedom-and-Growth.html",
            "relUrl": "/2019/03/07/Economic-Freedom-and-Growth.html",
            "date": " • Mar 7, 2019"
        }
        
    
  

  
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page9": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://antoniojurlina.github.io/portfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}